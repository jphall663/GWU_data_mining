# Materials for GWU DNSC 6279 and 6290

**DNSC 6279 ("Data Mining")** provides exposure to various data preprocessing, statistics, and machine learning techniques that can be used both to discover relationships in large data sets and to build predictive models. Techniques covered will include basic and analytical data preprocessing, regression models, decision trees, neural networks, clustering, association analysis, and basic text mining. Techniques will be presented in the context of data driven organizational decision making using statistical and machine learning approaches.

**DNSC 6290 ("Machine Learning")** provides a follow up course to DNSC 6279 that will expand on both the theoretical and practical aspects of subjects covered in the pre-requisite course while optionally introducing new materials. Techniques covered may include feature engineering, penalized regression, neural networks and deep learning, ensemble models including stacked generalization and super learner approaches, matrix factorization, model validation, and model interpretation. Classes will be taught as workshops where groups of students will apply lecture materials to the ongoing [Kaggle](https://www.kaggle.com) [Advanced Regression](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) and [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer) contests.

## Course Topics

| Topics |
|---|
| [Section 00: Intro and History](00_intro_and_history/00_intro_and_history.md) |
| [Section 01: Basic Data Prep](01_basic_data_prep/01_basic_data_prep.md) |
| [Section 02: Analytical Data Prep](02_analytical_data_prep/02_analytical_data_prep.md) |
| [Section 03: Regression](03_regression/03_regression.md) |
| [Section 04: Decision Trees and Ensembles](04_decision_trees/04_decision_trees.md) |
| [Section 05: Neural Networks](05_neural_networks/05_neural_networks.md) |
| [Section 06: Clustering](06_clustering/06_clustering.md) |
| [Section 07: Association Rules](07_association_rules/07_association_rules.md) |
| [Section 08: Text Mining](08_text_mining/08_text_mining.md) |
| [Section 09: Matrix Factorization](09_matrix_factorization/09_matrix_factorization.md)
| [Section 10: Model Interpretability](10_model_interpretability/10_model_interpretability.md)

#### Some external reference material
* [AutoML](https://github.com/jphall663/automl_resources)
* A Few Kaggle Grandmasters Pointers:
  * [How to become a Kaggle #1: An introduction to model stacking](https://www.youtube.com/watch?v=9Vk1rXLhG48) by [Marios Michailidis](https://www.kaggle.com/kazanova)
  * [Kaggle Tips](https://github.com/h2oai/h2o-meetups/blob/master/2016_12_15_SV_BigDataScience/2016_12_15_H2O_Meetup_Kaggle_Tips.pdf) by [Dmitry Larko](https://www.kaggle.com/dmitrylarko)
  * [Learn Kaggle techniques from Kaggle #1](https://www.youtube.com/watch?v=LgLcfZjNF44) by [Owen Zhang](https://www.kaggle.com/owenzhang1)
* [Data visualization](https://github.com/jphall663/basic_data_viz_rules_and_links)
* [Data science quick references](https://github.com/jphall663/ds_quick_refs)
* [Data science interview questions](https://github.com/jphall663/ds_interview_qs)
* [Python introductory materials](https://github.com/jphall663/bellarmine_py_intro)

## Course Syllabi

#### Pre-requisite Courses

* **DNSC 6279 ("Data Mining")**: Stochastics for Analytics I, Statistics for Analytics, or equivalent (JUD/DAD),
MSBA Program Candidacy or instructor approval.

* **DNSC 6290 ("Machine Learning")**: Stochastics for Analytics I, Statistics for Analytics, or equivalent (JUD/DAD), Data Mining,
MSBA Program Candidacy or instructor approval.

#### Instructor

Mr. Patrick Hall

**E-mail**: jphall@gwu.edu

**Twitter**: [@jpatrickhall](https://twitter.com/jpatrickhall)

**Linkedin**: https://www.linkedin.com/in/jpatrickhall/

**Office Hours**: Before lectures when business travel allows.

#### Copyrights and Licenses

Some teaching materials are copyrighted by the instructor. Some copyrights are owned by other individuals and entities.

Most code examples are copyrighted by the instructor and provided with an [MIT license](https://opensource.org/licenses/MIT), meaning they can be used for almost anything as long as the copyright and license notice are preserved. Some code examples are copyrighted by other entities, and usually provided with an [Apache Version 2 license](https://opensource.org/licenses/Apache-2.0). These code examples can be also used for nearly any purpose, even commercially, as long as the copyright and license notice are preserved.

#### Recommended Textbooks

###### DNSC 6279 ("Data Mining")

* [*Introduction to Data Mining*](http://www-users.cs.umn.edu/~kumar/dmbook/index.php), by Pang-Ning Tan, Michael Steinbach, and Vipin Kumar

* [*An Introduction to Statistical Learning with Applications in R*](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Fourth%20Printing.pdf), by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani

###### DNSC 6290 ("Machine Learning")

* [*Elements of Statistical Learning*](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf), by Trevor Hastie, Robert Tibshirani, and Jerome Friedman</br>

* [*Pattern Recognition and Machine Learning*](http://www.springer.com/us/book/9780387310732), by Christopher Bishop</br>
([Freely available PDF](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf))

* [*A Primer on Scientific Programming with Python*](http://www.springer.com/us/book/9783642549595), by Hans Petter Langtangen
  * [Related Free Materials](https://hplgit.github.io/primer.html/doc/pub/half/book.pdf)
  * [GWU Libraries EBook](https://link-springer-com.proxygw.wrlc.org/book/10.1007%2F978-3-662-49887-3)

#### Reading Assignments

The student is responsible for studying and understanding all assigned materials. If reading generates questions that are not discussed in class, the student has the responsibility of addressing the instructor privately or raising the issue in an appropriate digital medium.

#### Blackboard

Some materials for this class have personal or corporate copyrights or licenses that prevent them from being shared on GitHub. Those materials or other internal information will be shared with students via [Blackboard](https://blackboard.gwu.edu/).

#### Grading

###### DNSC 6279 ("Data Mining")

* The course grade will be based on homework assignments, quizzes, a final exam, and a team project. Each grading component is described in detail below.

* **Quizzes**: There will be several in class quizzes, typically every week. They will be based on current and prior assigned readings and material covered in the class sessions. No make up quizzes will be given. The lowest quiz grade will be dropped. Quizzes are individual assignments.

* **Homework Assignments**: You will be given several homework assignments during the semester. Homework assignments will typically require the use of software. A typical homework assignment will consist of a few problems with several parts. Homework assignments may be completed in groups. You may be given up to several weeks to complete the assignment. Late homework assignments may be rejected. In preparing your homework assignments, please follow these guidelines:
  * Ensure any submitted computer program solutions are commented and runnable in a standard Python, R, or SAS environment.
  * Ensure any written solutions are typed or easily readable by anyone.
  * Ensure a clear logical flow and mark your answers.
  * Print/type your name(s) on the top right hand corner of every page or in a header of any papers submitted.

* **Final Exam**: The final exam will be scheduled during finals' week. Graduate final exams are scheduled by the university late in the semester. The exam date will be made known at that time. No make up final exams will be given. The final exam is an individual assignment.

* **Project**: The project is designed to serve as an exercise in applying one or more of the data mining techniques covered in the course to analyze real life data sets. A primary objective is to understand the complexities that arise in mining large, real life datasets that are often inconsistent, incomplete, and unclean. Students can use a variety of software tools to perform the analysis, including standard Python, R, or SAS packages. This is a semester long project, and students have the option to work in 2 or 3 person teams. The deliverables include a formal project proposal (due mid-semester), and a final report (due at the end of the semester at the time of your final project presentation). Projects can be a group or individual assignment. As the project for this class, students may select:
  * A current [Kaggle contest](https://www.kaggle.com/)
  * Their MSBA practicum project

* **Grading Weights**
  * Quizzes: 25%
  * Homework assignments: 25%
  * Final exam: 25%
  * Project: 25%

###### DNSC 6290 ("Machine Learning")  

* **In class Participation**: As this will be a 6 week, workshop based course, student attendance and participation in class is expected.

* **Kaggle Performance**: Lecture materials and hands on workshop materials will be geared toward application to the [Kaggle](https://www.kaggle.com) [Advanced Regression](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) and [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer) contests. Students are expected to participate in these contests as individuals or in groups and to do reasonably well.

* **Public Github Contributions**: Students are expected to write code and generate other artifacts (i.e. notebooks, visualizations, markdown) and to store them in a publicly accessible GitHub repository (or other public location, i.e. personal website).

* **Grading Weights**
  * In class participation: 1/3
  * Kaggle Performance: 1/3
  * Public Github Contributions: 1/3

#### Academic Integrity

**If you are struggling with an assignment or class materials, require extra time for an assignment, or simply require additional assistance, see the instructor immediately.**

Cheating and plagiarism will not be tolerated. Any case will automatically result in loss of all the points for the assignment, and may be a reason for a failing grade and/or grounds for dismissal. In case of a group assignment, all group members will receive a zero grade.

Any suspected case of cheating or plagiarism or behavior in violation of the rules of this course will be reported to the Office of Academic Integrity. Students are expected to know and understand all college policies, especially the code of [academic integrity](http://www.gwu.edu/~ntegrity/code.html).

#### Disability Services

Please contact the [Disability Support Services](http://disabilitysupport.gwu.edu/) to establish eligibility and to coordinate reasonable accommodation.

#### Attendance

Regular attendance is expected. Students are held responsible for all of the work of the courses in which they are registered, and all absences must be excused by the instructor before provision is made to make up the work missed.

#### Class Policy Changes

The instructor reserves the right to revise any item on this syllabus, including, but not limited to any class policy, course outline or schedule, grading policy, tests, etc. Note that the requirements for deliverables may be clarified and expanded in class, via email, on GitHub, or on Blackboard. Students are expected to complete the deliverables incorporating such additions.

## Software

* [Anaconda Python](https://www.continuum.io/downloads) Python is an approachable, general purpose programming language with excellent add on libraries for math and data analysis. Anaconda Python is a commercial version of Python that bundles these add on packages (and many other packages) together with convenient development utilities like the Spyder IDE.

* [H2o.ai](http://www.h2o.ai) is a package of high performance functions and algorithms for preprocessing data and training statistical and machine learning models. It can be accessed without the need for coding through a standalone, web browser client or by installing additional coding interfaces for R and/or Python.

* [R](https://cran.r-project.org/) is a tremendously popular language for data analysis, with thousands of user contributed packages for different types of data analysis tasks.

* [R Studio](https://www.rstudio.com/products/rstudio/#Desktop) is the standard IDE for the R language.

* [SAS 9.4 and Enterprise Miner](http://www.sas.com/en_us/software/analytics/enterprise-miner.html) is a commercial package for preprocessing data and training statistical and machine learning models. Enterprise Miner allows for the construction of complex data mining workflows without writing code. Enterprise Miner is a proprietary commercial product and not freely available. You may access Enterprise Miner through the [SAS on Demand for Academics portal](https://odamid.oda.sas.com) or by contacting the [GWU Instructional Technology Lab](https://itl.gwu.edu/sas-software-distribution).

* [SAS 9.4 University Edition](http://www.sas.com/en_ph/software/university-edition/download-software.html) is a free edition of SAS' proprietary commercial data analysis software. SAS University Edition contains the newest version of several SAS software packages along with learning tools and utilities for new users. It also requires a virtual machine player which you may need to install separately.

* [TensorFlow](https://www.tensorflow.org/) + [Keras](https://keras.io/) are two of several popular deep learning toolkits and libraries; this particular combination will work on Windows. TensorFlow is a lower-level library for performing mathematical operations. It is GPU-enabled. (GPU support is optional but helpful for this class.) Keras is a higher level library that makes TensorFlow easier to use for building and training common deep learning architectures. They are both available as Python packages.

* [XGBoost](https://github.com/dmlc/xgboost) is an optimized and highly accurate library for gradient boosted regression and classification. There are Python and R packages available for available XGBoost. (I have found XGBoost is easiest to install as R an package, but if you get stuck with Python and Windows, you can try following the directions in [this blog post](https://datanoord.wordpress.com/2016/02/06/setup-xgboost-on-windows-python/).)

#### Using Git for this Material

You are welcome to use git and/or GitHub to save and manage your own copies of class materials.

The easiest way to do so is to download this entire repository as a zip file. However you will need to download a new copy of the repository whenever changes are made to this repository. To download the course repository, navigate to the [course GitHub repository (i.e. this page)](https://github.com/jphall663/GWU_data_mining) and click the 'Clone or Download' button and then select 'Download Zip'.

![alt text](readme_pics/download.png "Download this repo.")

If you would like to take advantage of the version control capabilities of git then you need to follow these steps.

###### Install required software

* [Git client](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)

* [Git lfs client](https://git-lfs.github.com)

###### Fork and pull materials

Navigate to the [course GitHub repository (i.e. this page)](https://github.com/jphall663/GWU_data_mining) and click the 'Fork' button.

![alt text](readme_pics/fork.png "Fork this repo!")

Enter the following statements on the git bash command line:

`$ cd <parent directory>`


`$ mkdir GWU_data_mining`


`$ cd GWU_data_mining`


`$ git init`


`$ git remote add origin https://github.com/<your username>/GWU_data_mining.git`


`$ git remote add upstream https://github.com/jphall663/GWU_data_mining.git`


`$ git pull origin master`


`$ git lfs install`


`$ git lfs track '*.jpg' '*.png' '*.csv' '*.sas7bdat'`

#### Docker

[Dockerfile](./anaconda_py35_h2o_xgboost_graphviz) to create Anaconda Python 3.5 environment with H2O, XGBoost, and GraphViz.

Start the image with:

`docker run -i -t -p 8888:8888 <image_id> /bin/bash -c "/opt/conda/bin/conda install jupyter -y --quiet && /opt/conda/bin/jupyter notebook --notebook-dir=/GWU_data_mining --ip='*' --port=8888 --no-browser"`
