## Section 09: Matrix factorization

Matrix factorization enables us to represent sparse or high-dimensional data
sets and high cardinality features with a small number of dense of numeric
features suitable for modeling and visualization.

#### Class Notes

* Basic PCA examples

  * [One component with back-projection](../02_analytical_data_prep/src/py_part_2_feature_extraction.ipynb)

  * [Iris data with visualization](src/py_part_9_iris_pca.ipynb)

  * [Kaggle House Prices example notebook](src/py_part_9_kaggle_GLRM_example.ipynb)

* [Advanced notes](notes/msba_2017_ml_week_5_FINAL.pdf)

#### Supplementary References

* [Generalized Low Rank Models (GLRM) with H2O](http://docs.h2o.ai/h2o-tutorials/latest-stable/tutorials/glrm/glrm-tutorial.html)

* [LibFM for Factorization Machines](http://libfm.org/)

***

* [*Elements of Statistical Learning*](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf)</br>
Sections 14.5 - 14.6, 14.8

* [*Pattern Recognition in Machine Learning*](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)</br>
Chapter 12

***

#### Generalized Low Rank Models (GLRM)

* [Generalized Low Rank Models (Book)](http://www.web.stanford.edu/~boyd/papers/pdf/glrm.pdf)</br>
by Madeleine Udell, Corinne Horn, Reza Zadeh, and Stephen Boyd

* [Generalized Low Rank Models (Paper)](https://stanford.edu/~rezab/nips2014workshop/submits/glrm.pdf)</br>
by Madeleine Udell, Corinne Horn, Reza Zadeh, and Stephen Boyd

* [Learning the Parts of Objects by Nonnegative Matrix Factorization](https://www.cs.princeton.edu/courses/archive/spring12/cos424/pdf/lee-seung.pdf)</br>
by Daniel D. Lee and H. Sebastian Seung

* [Sparse Principal Component Analysis](http://www.web.stanford.edu/~hastie/Papers/sparsepc.pdf)</br>
by Hui Zou, Trevor Hastie, and Robert Tibshirani

* [Robust Principal Component Analysis?](https://statweb.stanford.edu/~candes/papers/RobustPCA.pdf)</br>
by Emmanuel J. Candes, Xiaodong Li, Yi Ma, and John Wright

***

* [Factorization Machines](http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf)</br>
by Steffen Rendle

* [Near Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?](http://statweb.stanford.edu/~candes/papers/OptimalRecovery.pdf)</br>
by Emmanuel Candes and Terence Tao

***

* [SAS random projections example](https://github.com/jphall663/enlighten-apply/tree/master/SAS_UE_Random_Projections)

* [Quora answer regarding feature extraction](https://www.quora.com/How-do-you-attack-a-machine-learning-problem-with-a-large-number-of-features/answer/Patrick-Hall-4) 
