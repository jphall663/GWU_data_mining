{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License \n",
    "***\n",
    "Copyright (C) 2018 J. Patrick Hall, jphall@gwu.edu\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Simple multilayer perception (MLP) example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import urllib.request as urllib2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set simple hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARN_RATE = 0.005\n",
    "ITERATIONS = 600\n",
    "HIDDEN_UNITS = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch simple Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inputs:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]]\n",
      "\n",
      "\n",
      "Data target:\n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# load and preprocess Iris data set \n",
    "# easy binomial classification task: seperate Setosa irises from Versicolor irises\n",
    "\n",
    "# fetch data from UCI repository\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "connection = urllib2.urlopen(url)\n",
    "raw = connection.read()\n",
    "\n",
    "# initialize empty X and y arrays\n",
    "X = np.zeros((100, 4))\n",
    "y = np.zeros((100, 1))\n",
    "\n",
    "# load iris data into X and y arrays \n",
    "row_idx = 0\n",
    "for line in str(raw)[2:-5].split('\\\\n'):\n",
    "    line = line.replace('Iris-setosa', '1').replace('Iris-versicolor', '0')\n",
    "    line = line.split(',')\n",
    "    # remove Virginica irises from data set\n",
    "    if line[-1] != 'Iris-virginica':\n",
    "        line = np.asarray(line)\n",
    "        X[row_idx, :] = line[:-1]\n",
    "        y[row_idx, :] = line[-1]\n",
    "        row_idx += 1\n",
    "\n",
    "        \n",
    "print('Data inputs:\\n', X)\n",
    "print('\\n')\n",
    "print('Data target:\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP architecture is: 4 input units -> 30 hidden units -> 1 output units.\n",
      "\n",
      "There are 120 hidden weights to optimize.\n",
      "Initial hidden weights:\n",
      " [[ 4.29616093e-01 -1.83624445e-01 -3.16081188e-01 -2.95439721e-01\n",
      "   6.77250291e-02  9.55447030e-02  4.64514520e-01  1.53177097e-01\n",
      "   2.48906638e-01  1.53569871e-01  2.47714809e-01  4.61306736e-01\n",
      "  -4.91611702e-01 -3.93555623e-01 -2.01296286e-01  1.56411183e-01\n",
      "   3.09812553e-01  3.72175914e-01  4.64647597e-01  2.23685347e-01\n",
      "   1.42475328e-01  2.17453621e-01 -3.24009928e-02 -1.74415322e-01\n",
      "  -6.03553941e-02  2.29689083e-01  4.94014586e-01  1.76873712e-01\n",
      "   2.90822518e-01 -3.29085742e-01]\n",
      " [-4.73150724e-01  3.00370244e-01  4.03722538e-01 -4.75323790e-01\n",
      "  -8.25268155e-03  2.62551673e-02  9.63660104e-02 -4.48042455e-01\n",
      "   3.95089528e-01  2.28266180e-01  3.18350011e-01  2.22752834e-04\n",
      "   3.10189409e-01 -4.04031474e-01 -2.81049956e-01 -2.41280938e-01\n",
      "  -3.18942460e-02 -4.06267974e-02  2.09509780e-01 -3.21946994e-01\n",
      "   3.14498844e-02 -3.32257771e-01  2.68813918e-01  4.28170549e-01\n",
      "   1.09493658e-01 -3.49816505e-01 -1.03732963e-02 -1.22655046e-01\n",
      "   3.48601412e-01  4.11097229e-01]\n",
      " [-1.16151279e-01 -1.84504097e-01  6.83941528e-02 -3.12181965e-01\n",
      "  -3.74158456e-01  1.87595805e-01  2.99606718e-01  7.35365652e-02\n",
      "   4.73229982e-01  1.34054377e-01  3.88421725e-01 -4.58524124e-03\n",
      "  -1.48383470e-01  2.14230369e-01  3.92911645e-03 -2.74362393e-01\n",
      "  -2.55025560e-01  2.92800700e-01 -4.82758549e-03  4.15093673e-01\n",
      "   4.45371834e-01  3.32322297e-02 -2.47507405e-01  2.20862058e-01\n",
      "  -1.32561236e-01 -1.35155709e-03 -2.73424953e-01 -1.46434353e-01\n",
      "   1.50851787e-01 -1.87067105e-01]\n",
      " [ 2.68735447e-01  2.81837103e-01  3.52409483e-01  4.49905740e-01\n",
      "  -3.92677088e-01  4.10725356e-01 -1.63944838e-01  3.26380427e-01\n",
      "   3.98100635e-01 -4.57284696e-01 -3.04205001e-01 -2.05498678e-01\n",
      "   1.26999881e-01 -4.13776895e-01 -3.57054980e-01  1.58265192e-02\n",
      "   1.89341330e-01  3.56625811e-01  1.47361683e-01  8.16186755e-02\n",
      "   2.11115955e-01 -2.47583143e-01  4.00159683e-01 -5.77063071e-02\n",
      "  -4.79479175e-01  4.59661014e-01  1.52225422e-01  1.32062501e-02\n",
      "   1.82356383e-01 -1.04596094e-02]]\n",
      "\n",
      "There are 30 output weights to optimize.\n",
      "Initial output weights:\n",
      " [[ 0.42649017]\n",
      " [ 0.01587977]\n",
      " [-0.42784012]\n",
      " [ 0.0675083 ]\n",
      " [ 0.11524318]\n",
      " [ 0.44154629]\n",
      " [-0.08463665]\n",
      " [-0.23556003]\n",
      " [-0.40260683]\n",
      " [-0.01415578]\n",
      " [-0.03533714]\n",
      " [-0.47024068]\n",
      " [ 0.19427746]\n",
      " [ 0.21694711]\n",
      " [ 0.22981142]\n",
      " [-0.08564898]\n",
      " [-0.48490116]\n",
      " [ 0.40897516]\n",
      " [ 0.28937872]\n",
      " [-0.33480083]\n",
      " [-0.18721404]\n",
      " [ 0.11094531]\n",
      " [-0.13550971]\n",
      " [-0.34396141]\n",
      " [-0.32269619]\n",
      " [ 0.36788967]\n",
      " [-0.20990533]\n",
      " [ 0.08517962]\n",
      " [-0.04600512]\n",
      " [-0.08882187]]\n",
      "\n",
      "Initial yhat:\n",
      " [[0.24753092]\n",
      " [0.25931333]\n",
      " [0.25272927]\n",
      " [0.25386176]\n",
      " [0.2440762 ]\n",
      " [0.24032274]\n",
      " [0.24705247]\n",
      " [0.24888208]\n",
      " [0.25845649]\n",
      " [0.25535009]\n",
      " [0.24460842]\n",
      " [0.24689153]\n",
      " [0.25774061]\n",
      " [0.25550082]\n",
      " [0.24242968]\n",
      " [0.23189508]\n",
      " [0.24214685]\n",
      " [0.24835111]\n",
      " [0.24486826]\n",
      " [0.24023051]\n",
      " [0.25156733]\n",
      " [0.24358553]\n",
      " [0.24275981]\n",
      " [0.25381345]\n",
      " [0.2458832 ]\n",
      " [0.25925736]\n",
      " [0.25005186]\n",
      " [0.24796707]\n",
      " [0.25104261]\n",
      " [0.25147818]\n",
      " [0.25494329]\n",
      " [0.25393003]\n",
      " [0.23195235]\n",
      " [0.23350859]\n",
      " [0.25535009]\n",
      " [0.25562701]\n",
      " [0.25168511]\n",
      " [0.25535009]\n",
      " [0.25609123]\n",
      " [0.24972576]\n",
      " [0.24797449]\n",
      " [0.2776847 ]\n",
      " [0.25058758]\n",
      " [0.24903445]\n",
      " [0.23953033]\n",
      " [0.25930852]\n",
      " [0.23899369]\n",
      " [0.25154877]\n",
      " [0.24368678]\n",
      " [0.25197602]\n",
      " [0.27088801]\n",
      " [0.26591219]\n",
      " [0.27252074]\n",
      " [0.28258432]\n",
      " [0.27653197]\n",
      " [0.27113881]\n",
      " [0.26290388]\n",
      " [0.27584151]\n",
      " [0.27499745]\n",
      " [0.27040464]\n",
      " [0.28762903]\n",
      " [0.26713655]\n",
      " [0.28820243]\n",
      " [0.27145341]\n",
      " [0.26738991]\n",
      " [0.270671  ]\n",
      " [0.26555881]\n",
      " [0.27362861]\n",
      " [0.28954755]\n",
      " [0.27758806]\n",
      " [0.26282735]\n",
      " [0.27338843]\n",
      " [0.28309697]\n",
      " [0.27404529]\n",
      " [0.27322464]\n",
      " [0.27231577]\n",
      " [0.27909192]\n",
      " [0.27316868]\n",
      " [0.2705194 ]\n",
      " [0.27533592]\n",
      " [0.27959107]\n",
      " [0.27939121]\n",
      " [0.27374183]\n",
      " [0.27643558]\n",
      " [0.26447254]\n",
      " [0.25827335]\n",
      " [0.27077494]\n",
      " [0.28781218]\n",
      " [0.26491407]\n",
      " [0.27725351]\n",
      " [0.27499742]\n",
      " [0.26879769]\n",
      " [0.27640164]\n",
      " [0.27914974]\n",
      " [0.27275717]\n",
      " [0.26548443]\n",
      " [0.26819554]\n",
      " [0.27172772]\n",
      " [0.27471698]\n",
      " [0.27069514]]\n",
      "\n",
      "Training ...\n",
      "Iteration  100, Error:  0.16\n",
      "Iteration  200, Error:  0.08\n",
      "Iteration  300, Error:  0.07\n",
      "Iteration  400, Error:  0.05\n",
      "Iteration  500, Error:  0.05\n",
      "Iteration  600, Error:  0.04\n",
      "Maximum iterations reached, done.\n"
     ]
    }
   ],
   "source": [
    "# very simple MLP routine\n",
    "# with logistic activation for hidden and output layer\n",
    "\n",
    "# set random seed\n",
    "# always do this when working with random numbers\n",
    "np.random.seed(12345)\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "hidden_weights = np.random.random((4, HIDDEN_UNITS)) - 0.5 # 4 X HIDDEN_UNITS weights in hidden layer\n",
    "output_weights = np.random.random((HIDDEN_UNITS, 1)) - 0.5 # HIDDEN_UNITS X 1 weights in output layer\n",
    "\n",
    "print('MLP architecture is: 4 input units -> %d hidden units -> 1 output units.' % HIDDEN_UNITS)\n",
    "print()\n",
    "print('There are %d hidden weights to optimize.' % (4 * HIDDEN_UNITS))\n",
    "print('Initial hidden weights:\\n', hidden_weights)\n",
    "print()\n",
    "print('There are %d output weights to optimize.' % HIDDEN_UNITS)\n",
    "print('Initial output weights:\\n', output_weights)\n",
    "\n",
    "# initialize empty pandas DataFrame to hold iteration scores\n",
    "iter_frame = pd.DataFrame(columns=['Iteration', 'Error'])\n",
    "\n",
    "# activation function\n",
    "def logistic_activation_function(weights_times_inputs):\n",
    "\n",
    "    return 1 / (1 + np.exp(-weights_times_inputs))\n",
    "\n",
    "# trainign loop\n",
    "for iteration in range(0, ITERATIONS):\n",
    "\n",
    "    ### feed-forward phase ##########\n",
    "    # run data through input, hidden, and output layers\n",
    "    \n",
    "    input_layer = X\n",
    "    hidden_layer = logistic_activation_function(np.dot(input_layer, hidden_weights))\n",
    "    output_layer = logistic_activation_function(np.dot(hidden_layer, output_weights))\n",
    "    \n",
    "    if iteration == 0:\n",
    "        print('\\nInitial yhat:\\n', output_layer)\n",
    "        print()    \n",
    "        print('Training ...')\n",
    "            \n",
    "    ### evaluate error function ##########\n",
    "    output_logloss_error = -y * np.log(output_layer) + (1 - y)*np.log(1 - output_layer)\n",
    "    if ((iteration + 1) % 100) == 0:\n",
    "        print('Iteration %4i, Error: %5.2f' % (iteration + 1, np.sum(output_logloss_error)))\n",
    "    \n",
    "    # record iteration and error\n",
    "    iter_frame = iter_frame.append({'Iteration': iteration,\n",
    "                                    'Error': np.sum(output_logloss_error)}, \n",
    "                                   ignore_index=True)    \n",
    "        \n",
    "    ### back-propogation phase ##########\n",
    "    # back-propogate error from output layer to hidden layer \n",
    "    # weight's output delta and input activation are multiplied to find the gradient of the weights\n",
    "    # due to chain rule\n",
    "    \n",
    "    output_loss_gradient = output_layer - y # logloss derivative\n",
    "    output_layer_gradient = output_layer * (1 - output_layer) # output sigmoid derivative\n",
    "    output_input = hidden_layer # linear combo derivative\n",
    "    output_total_gradient = output_input.T.dot(output_loss_gradient * output_layer_gradient)\n",
    "    \n",
    "    hidden_loss_gradient = output_loss_gradient.dot(output_weights.T) # backprop error/logloss derivative\n",
    "    hidden_layer_gradient = hidden_layer * (1 - hidden_layer) # hidden sigmoid derivative\n",
    "    hidden_input = input_layer # linear combo derivative\n",
    "    hidden_total_gradient = hidden_input.T.dot(hidden_loss_gradient * hidden_layer_gradient)\n",
    "    \n",
    "    ### update weights based on gradient ##########\n",
    "    # update weights in direction that minimizes error using layerwise gradients\n",
    "    # (input layer is never updated, b/c it is the data itself)\n",
    "    # scale by learning rate\n",
    "    output_weights -= LEARN_RATE * output_total_gradient\n",
    "    hidden_weights -= LEARN_RATE * hidden_total_gradient\n",
    "\n",
    "print('Maximum iterations reached, done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y      yhat\n",
       "0   1.0  0.984989\n",
       "1   1.0  0.977354\n",
       "2   1.0  0.982045\n",
       "3   1.0  0.973939\n",
       "4   1.0  0.985555\n",
       "5   1.0  0.983661\n",
       "6   1.0  0.981078\n",
       "7   1.0  0.981839\n",
       "8   1.0  0.970961\n",
       "9   1.0  0.977764\n",
       "10  1.0  0.986127\n",
       "11  1.0  0.978358\n",
       "12  1.0  0.978206\n",
       "13  1.0  0.982752\n",
       "14  1.0  0.990286\n",
       "15  1.0  0.989420\n",
       "16  1.0  0.988267\n",
       "17  1.0  0.984252\n",
       "18  1.0  0.984454\n",
       "19  1.0  0.985497\n",
       "20  1.0  0.979053\n",
       "21  1.0  0.983857\n",
       "22  1.0  0.988607\n",
       "23  1.0  0.968699\n",
       "24  1.0  0.965659\n",
       "25  1.0  0.970417\n",
       "26  1.0  0.976652\n",
       "27  1.0  0.983781\n",
       "28  1.0  0.984353\n",
       "29  1.0  0.973318\n",
       "..  ...       ...\n",
       "70  0.0  0.011904\n",
       "71  0.0  0.022317\n",
       "72  0.0  0.010491\n",
       "73  0.0  0.013013\n",
       "74  0.0  0.018555\n",
       "75  0.0  0.017796\n",
       "76  0.0  0.012652\n",
       "77  0.0  0.011271\n",
       "78  0.0  0.013743\n",
       "79  0.0  0.042274\n",
       "80  0.0  0.020388\n",
       "81  0.0  0.024247\n",
       "82  0.0  0.022913\n",
       "83  0.0  0.009940\n",
       "84  0.0  0.013330\n",
       "85  0.0  0.016894\n",
       "86  0.0  0.014403\n",
       "87  0.0  0.012897\n",
       "88  0.0  0.020525\n",
       "89  0.0  0.016321\n",
       "90  0.0  0.013353\n",
       "91  0.0  0.014052\n",
       "92  0.0  0.019172\n",
       "93  0.0  0.033475\n",
       "94  0.0  0.015667\n",
       "95  0.0  0.019868\n",
       "96  0.0  0.017776\n",
       "97  0.0  0.017826\n",
       "98  0.0  0.070846\n",
       "99  0.0  0.018372\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_yhat_frame = pd.DataFrame(columns = ['y', 'yhat'])\n",
    "y_yhat_frame['y'] = y.reshape(-1)\n",
    "y_yhat_frame['yhat'] = output_layer.reshape(-1)\n",
    "y_yhat_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc6da92ee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "_ = iter_frame.plot(kind='line', x='Iteration', y='Error', title='Iteration Chart')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
