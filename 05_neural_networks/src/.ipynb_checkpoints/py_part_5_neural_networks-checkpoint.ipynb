{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License \n",
    "***\n",
    "Copyright (C) 2017 J. Patrick Hall, jphall@gwu.edu\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import h2o \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display matplotlib graphics in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_112\"; Java(TM) SE Runtime Environment (build 1.8.0_112-b16); Java HotSpot(TM) 64-Bit Server VM (build 25.112-b16, mixed mode)\n",
      "  Starting server from /Users/phall/anaconda/lib/python3.5/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/tc/0ss1l73113j3wdyjsxmy1j2r0000gn/T/tmpu7y9qi1u\n",
      "  JVM stdout: /var/folders/tc/0ss1l73113j3wdyjsxmy1j2r0000gn/T/tmpu7y9qi1u/h2o_phall_started_from_python.out\n",
      "  JVM stderr: /var/folders/tc/0ss1l73113j3wdyjsxmy1j2r0000gn/T/tmpu7y9qi1u/h2o_phall_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.3.4</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 2 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_phall_sxxj60</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.5.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster version:        3.10.3.4\n",
       "H2O cluster version age:    1 month and 2 days\n",
       "H2O cluster name:           H2O_from_python_phall_sxxj60\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "Python version:             3.5.2 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start and connect to h2o server\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load clean data\n",
    "path = '/Users/phall/workspace/GWU_data_mining/03_regression/data/loan_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define input variable measurement levels \n",
    "# strings automatically parsed as enums (nominal)\n",
    "# numbers automatically parsed as numeric\n",
    "col_types = {'bad_loan': 'enum'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "frame = h2o.import_file(path=path, col_types=col_types) # multi-threaded import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:163987\n",
      "Cols:18\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>id               </th><th>bad_loan  </th><th>GRP_REP_home_ownership  </th><th>GRP_addr_state    </th><th>GRP_home_ownership  </th><th>GRP_purpose       </th><th>GRP_verification_status  </th><th>_WARN_  </th><th>STD_IMP_REP_annual_inc  </th><th>STD_IMP_REP_delinq_2yrs  </th><th>STD_IMP_REP_dti      </th><th>STD_IMP_REP_emp_length  </th><th>STD_IMP_REP_int_rate  </th><th>STD_IMP_REP_loan_amnt  </th><th>STD_IMP_REP_longest_credit_lengt  </th><th>STD_IMP_REP_revol_util  </th><th>STD_IMP_REP_term_length  </th><th>STD_IMP_REP_total_acc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int              </td><td>enum      </td><td>int                     </td><td>int               </td><td>int                 </td><td>int               </td><td>int                      </td><td>int     </td><td>real                    </td><td>real                     </td><td>real                 </td><td>real                    </td><td>real                  </td><td>real                   </td><td>real                              </td><td>real                    </td><td>real                     </td><td>real                   </td></tr>\n",
       "<tr><td>mins   </td><td>10001.0          </td><td>          </td><td>1.0                     </td><td>1.0               </td><td>1.0                 </td><td>1.0               </td><td>1.0                      </td><td>NaN     </td><td>-1.767455639            </td><td>-0.39219617              </td><td>-2.119639396         </td><td>-1.6213902740000001     </td><td>-1.907046215          </td><td>-1.587129405           </td><td>-2.22445124                       </td><td>-2.164541326            </td><td>-0.516495577             </td><td>-2.058861889           </td></tr>\n",
       "<tr><td>mean   </td><td>91994.0          </td><td>          </td><td>2.5740028172964924      </td><td>11.409337325519703</td><td>2.5740028172964924  </td><td>3.2449401476946345</td><td>2.340356247751345        </td><td>0.0     </td><td>2.38744452882879e-11    </td><td>2.2959296297769782e-12   </td><td>6.807013811211564e-11</td><td>-3.566867876239133e-11  </td><td>-8.948753565861857e-12</td><td>8.311927579716105e-11  </td><td>5.0612534090153816e-11            </td><td>-1.4734128080190765e-11 </td><td>-1.5009542966560638e-10  </td><td>8.060924856225354e-13  </td></tr>\n",
       "<tr><td>maxs   </td><td>173987.0         </td><td>          </td><td>5.0                     </td><td>37.0              </td><td>5.0                 </td><td>14.0              </td><td>3.0                      </td><td>NaN     </td><td>4.6180619798            </td><td>4.1566950661             </td><td>3.0371487270000004   </td><td>1.2288169612            </td><td>2.8376799992          </td><td>2.7671323946           </td><td>3.1431598296                      </td><td>3.0363495275            </td><td>1.9718787627             </td><td>3.0684672884           </td></tr>\n",
       "<tr><td>sigma  </td><td>47339.11363414683</td><td>          </td><td>0.6675260435449262      </td><td>9.971926133461404 </td><td>0.6675260435449262  </td><td>2.2672892075259754</td><td>0.5040864341768772       </td><td>-0.0    </td><td>0.9999999999982868      </td><td>0.9999999999212518       </td><td>1.0000000000037712   </td><td>1.0000000000339833      </td><td>1.0000000000199503    </td><td>0.999999999985285      </td><td>0.9999999999850594                </td><td>1.000000000017688       </td><td>1.0000000000642086       </td><td>1.0000000000331841     </td></tr>\n",
       "<tr><td>zeros  </td><td>0                </td><td>          </td><td>0                       </td><td>0                 </td><td>0                   </td><td>0                 </td><td>0                        </td><td>0       </td><td>0                       </td><td>0                        </td><td>0                    </td><td>0                       </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                       </td><td>0                        </td><td>0                      </td></tr>\n",
       "<tr><td>missing</td><td>0                </td><td>0         </td><td>0                       </td><td>0                 </td><td>0                   </td><td>0                 </td><td>0                        </td><td>163987  </td><td>0                       </td><td>0                        </td><td>0                    </td><td>0                       </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                       </td><td>0                        </td><td>0                      </td></tr>\n",
       "<tr><td>0      </td><td>10001.0          </td><td>0         </td><td>3.0                     </td><td>14.0              </td><td>3.0                 </td><td>3.0               </td><td>2.0                      </td><td>nan     </td><td>-1.1992995020000001     </td><td>-0.39219617              </td><td>1.5712460425         </td><td>1.2288169612            </td><td>-0.7047730510000001   </td><td>-1.019182214           </td><td>1.6839024850000002                </td><td>1.1858716502            </td><td>-0.516495577             </td><td>-1.359278248           </td></tr>\n",
       "<tr><td>1      </td><td>10002.0          </td><td>1         </td><td>3.0                     </td><td>10.0              </td><td>3.0                 </td><td>8.0               </td><td>2.0                      </td><td>nan     </td><td>-1.04507688             </td><td>-0.39219617              </td><td>-1.9861534850000002  </td><td>-1.6213902740000001     </td><td>0.3572732234          </td><td>-1.3347084310000001    </td><td>-0.42059567400000003              </td><td>-1.7882703350000002     </td><td>1.9718787627             </td><td>-1.7965180230000002    </td></tr>\n",
       "<tr><td>2      </td><td>10003.0          </td><td>0         </td><td>3.0                     </td><td>7.0               </td><td>3.0                 </td><td>7.0               </td><td>3.0                      </td><td>nan     </td><td>-1.501267394            </td><td>-0.39219617              </td><td>-0.9556422520000001  </td><td>1.2288169612            </td><td>0.5158905241          </td><td>-1.34732948            </td><td>-0.7212382690000001               </td><td>1.7782983174            </td><td>-0.516495577             </td><td>-1.271830292           </td></tr>\n",
       "<tr><td>3      </td><td>10004.0          </td><td>0         </td><td>3.0                     </td><td>2.0               </td><td>3.0                 </td><td>4.0               </td><td>2.0                      </td><td>nan     </td><td>-0.303921333            </td><td>-0.39219617              </td><td>0.5500788236         </td><td>1.2288169612            </td><td>-0.051913437          </td><td>-0.388129779           </td><td>0.0303682169                      </td><td>0.0325652593            </td><td>-0.516495577             </td><td>1.089264497            </td></tr>\n",
       "<tr><td>4      </td><td>10005.0          </td><td>0         </td><td>3.0                     </td><td>14.0              </td><td>3.0                 </td><td>10.0              </td><td>2.0                      </td><td>nan     </td><td>-0.890854259            </td><td>-0.39219617              </td><td>-0.624597193         </td><td>-0.7663281030000001     </td><td>-1.3369434530000002   </td><td>-1.019182214           </td><td>-0.8220262690000001               </td><td>-1.0317254690000002     </td><td>-0.516495577             </td><td>-1.0969343820000002    </td></tr>\n",
       "<tr><td>5      </td><td>10006.0          </td><td>0         </td><td>3.0                     </td><td>2.0               </td><td>3.0                 </td><td>8.0               </td><td>2.0                      </td><td>nan     </td><td>-0.5824090160000001     </td><td>-0.39219617              </td><td>-1.4054897720000001  </td><td>0.9437962377            </td><td>1.1319693155000001    </td><td>-1.271603188           </td><td>-1.623166051                      </td><td>1.3379811999            </td><td>-0.516495577             </td><td>-1.7965180230000002    </td></tr>\n",
       "<tr><td>6      </td><td>10007.0          </td><td>1         </td><td>4.0                     </td><td>2.0               </td><td>4.0                 </td><td>7.0               </td><td>2.0                      </td><td>nan     </td><td>-0.788039178            </td><td>-0.39219617              </td><td>-1.37879259          </td><td>-0.48130738             </td><td>1.7388529011          </td><td>-0.9434559220000001    </td><td>-1.17220216                       </td><td>-0.8596015050000001     </td><td>1.9718787627             </td><td>-1.0094864270000001    </td></tr>\n",
       "<tr><td>7      </td><td>10008.0          </td><td>1         </td><td>3.0                     </td><td>4.0               </td><td>3.0                 </td><td>4.0               </td><td>2.0                      </td><td>nan     </td><td>-1.430633434            </td><td>-0.39219617              </td><td>0.2937858745         </td><td>-1.6213902740000001     </td><td>-0.235817553          </td><td>-0.971853281           </td><td>-1.17220216                       </td><td>-0.703489072            </td><td>1.9718787627             </td><td>-1.883965979           </td></tr>\n",
       "<tr><td>8      </td><td>10009.0          </td><td>0         </td><td>4.0                     </td><td>14.0              </td><td>4.0                 </td><td>2.0               </td><td>3.0                      </td><td>nan     </td><td>0.0344814697            </td><td>-0.39219617              </td><td>0.032153489          </td><td>-0.196286656            </td><td>0.2147475328          </td><td>-0.8298664840000001    </td><td>-0.270274377                      </td><td>-1.339947451            </td><td>1.9718787627             </td><td>-0.135006875           </td></tr>\n",
       "<tr><td>9      </td><td>10010.0          </td><td>0         </td><td>4.0                     </td><td>2.0               </td><td>4.0                 </td><td>2.0               </td><td>2.0                      </td><td>nan     </td><td>0.1115927805            </td><td>-0.39219617              </td><td>-0.680661276         </td><td>1.2288169612            </td><td>-0.235817553          </td><td>-0.13570880500000002   </td><td>1.0826172966                      </td><td>0.5213930910000001      </td><td>-0.516495577             </td><td>0.8269206315000001     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into 40% training, 30% validation, and 30% test\n",
    "train, valid, test = frame.split_frame([0.4, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_loan\n",
      "['GRP_REP_home_ownership', 'GRP_addr_state', 'GRP_home_ownership', 'GRP_purpose', 'GRP_verification_status', 'STD_IMP_REP_annual_inc', 'STD_IMP_REP_delinq_2yrs', 'STD_IMP_REP_dti', 'STD_IMP_REP_emp_length', 'STD_IMP_REP_int_rate', 'STD_IMP_REP_loan_amnt', 'STD_IMP_REP_longest_credit_lengt', 'STD_IMP_REP_revol_util', 'STD_IMP_REP_term_length', 'STD_IMP_REP_total_acc']\n"
     ]
    }
   ],
   "source": [
    "# assign target and inputs\n",
    "y = 'bad_loan'\n",
    "X = [name for name in frame.columns if name not in ['id', '_WARN_', y]]\n",
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set target to factor - for binary classification\n",
    "train[y] = train[y].asfactor()\n",
    "valid[y] = valid[y].asfactor()\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  nn_model\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.14411464647275385\n",
      "RMSE: 0.3796243491568393\n",
      "LogLoss: 0.4545508130295154\n",
      "Mean Per-Class Error: 0.3641766804848612\n",
      "AUC: 0.6879894198982001\n",
      "Gini: 0.3759788397964001\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.20919837042173123: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>5628.0</td>\n",
       "<td>2396.0</td>\n",
       "<td>0.2986</td>\n",
       "<td> (2396.0/8024.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>818.0</td>\n",
       "<td>1082.0</td>\n",
       "<td>0.4305</td>\n",
       "<td> (818.0/1900.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>6446.0</td>\n",
       "<td>3478.0</td>\n",
       "<td>0.3239</td>\n",
       "<td> (3214.0/9924.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ---------------\n",
       "0      5628  2396  0.2986   (2396.0/8024.0)\n",
       "1      818   1082  0.4305   (818.0/1900.0)\n",
       "Total  6446  3478  0.3239   (3214.0/9924.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2091984</td>\n",
       "<td>0.4023801</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1311033</td>\n",
       "<td>0.5748118</td>\n",
       "<td>311.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2699799</td>\n",
       "<td>0.3646270</td>\n",
       "<td>145.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4676336</td>\n",
       "<td>0.8089480</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.4876967</td>\n",
       "<td>0.7142857</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0641674</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.4960472</td>\n",
       "<td>0.9998754</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2237859</td>\n",
       "<td>0.2257185</td>\n",
       "<td>192.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1905967</td>\n",
       "<td>0.6314806</td>\n",
       "<td>234.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1748815</td>\n",
       "<td>0.6358233</td>\n",
       "<td>254.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.209198     0.40238   210\n",
       "max f2                       0.131103     0.574812  311\n",
       "max f0point5                 0.26998      0.364627  145\n",
       "max accuracy                 0.467634     0.808948  7\n",
       "max precision                0.487697     0.714286  2\n",
       "max recall                   0.0641674    1         396\n",
       "max specificity              0.496047     0.999875  0\n",
       "max absolute_mcc             0.223786     0.225718  192\n",
       "max min_per_class_accuracy   0.190597     0.631481  234\n",
       "max mean_per_class_accuracy  0.174882     0.635823  254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.15 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100766</td>\n",
       "<td>0.4433253</td>\n",
       "<td>2.6115789</td>\n",
       "<td>2.6115789</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.0263158</td>\n",
       "<td>161.1578947</td>\n",
       "<td>161.1578947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200524</td>\n",
       "<td>0.4216453</td>\n",
       "<td>2.3741627</td>\n",
       "<td>2.4934673</td>\n",
       "<td>0.4545455</td>\n",
       "<td>0.4773869</td>\n",
       "<td>0.0236842</td>\n",
       "<td>0.05</td>\n",
       "<td>137.4162679</td>\n",
       "<td>149.3467337</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300282</td>\n",
       "<td>0.4054876</td>\n",
       "<td>2.6907177</td>\n",
       "<td>2.5589968</td>\n",
       "<td>0.5151515</td>\n",
       "<td>0.4899329</td>\n",
       "<td>0.0268421</td>\n",
       "<td>0.0768421</td>\n",
       "<td>169.0717703</td>\n",
       "<td>155.8996821</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400040</td>\n",
       "<td>0.3912729</td>\n",
       "<td>1.8993301</td>\n",
       "<td>2.3944956</td>\n",
       "<td>0.3636364</td>\n",
       "<td>0.4584383</td>\n",
       "<td>0.0189474</td>\n",
       "<td>0.0957895</td>\n",
       "<td>89.9330144</td>\n",
       "<td>139.4495559</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500806</td>\n",
       "<td>0.3758540</td>\n",
       "<td>2.1937263</td>\n",
       "<td>2.3540993</td>\n",
       "<td>0.42</td>\n",
       "<td>0.4507042</td>\n",
       "<td>0.0221053</td>\n",
       "<td>0.1178947</td>\n",
       "<td>119.3726316</td>\n",
       "<td>135.4099333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000605</td>\n",
       "<td>0.3265151</td>\n",
       "<td>1.8428480</td>\n",
       "<td>2.0987311</td>\n",
       "<td>0.3528226</td>\n",
       "<td>0.4018127</td>\n",
       "<td>0.0921053</td>\n",
       "<td>0.21</td>\n",
       "<td>84.2848048</td>\n",
       "<td>109.8731118</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500403</td>\n",
       "<td>0.2928796</td>\n",
       "<td>1.6322368</td>\n",
       "<td>1.9433375</td>\n",
       "<td>0.3125</td>\n",
       "<td>0.3720618</td>\n",
       "<td>0.0815789</td>\n",
       "<td>0.2915789</td>\n",
       "<td>63.2236842</td>\n",
       "<td>94.3337457</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000202</td>\n",
       "<td>0.2654448</td>\n",
       "<td>1.6532980</td>\n",
       "<td>1.8708641</td>\n",
       "<td>0.3165323</td>\n",
       "<td>0.3581864</td>\n",
       "<td>0.0826316</td>\n",
       "<td>0.3742105</td>\n",
       "<td>65.3297963</td>\n",
       "<td>87.0864112</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999798</td>\n",
       "<td>0.2251197</td>\n",
       "<td>1.3637076</td>\n",
       "<td>1.7018687</td>\n",
       "<td>0.2610887</td>\n",
       "<td>0.3258314</td>\n",
       "<td>0.1363158</td>\n",
       "<td>0.5105263</td>\n",
       "<td>36.3707555</td>\n",
       "<td>70.1868713</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000403</td>\n",
       "<td>0.1952777</td>\n",
       "<td>1.0467356</td>\n",
       "<td>1.5380029</td>\n",
       "<td>0.2004028</td>\n",
       "<td>0.2944584</td>\n",
       "<td>0.1047368</td>\n",
       "<td>0.6152632</td>\n",
       "<td>4.6735570</td>\n",
       "<td>53.8002917</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1709584</td>\n",
       "<td>1.0372602</td>\n",
       "<td>1.4378947</td>\n",
       "<td>0.1985887</td>\n",
       "<td>0.2752922</td>\n",
       "<td>0.1036842</td>\n",
       "<td>0.7189474</td>\n",
       "<td>3.7260187</td>\n",
       "<td>43.7894737</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999597</td>\n",
       "<td>0.1488687</td>\n",
       "<td>0.8266490</td>\n",
       "<td>1.3360547</td>\n",
       "<td>0.1582661</td>\n",
       "<td>0.2557944</td>\n",
       "<td>0.0826316</td>\n",
       "<td>0.8015789</td>\n",
       "<td>-17.3351019</td>\n",
       "<td>33.6054665</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000202</td>\n",
       "<td>0.1297643</td>\n",
       "<td>0.7679567</td>\n",
       "<td>1.2548511</td>\n",
       "<td>0.1470292</td>\n",
       "<td>0.2402476</td>\n",
       "<td>0.0768421</td>\n",
       "<td>0.8784211</td>\n",
       "<td>-23.2043250</td>\n",
       "<td>25.4851091</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999798</td>\n",
       "<td>0.1111519</td>\n",
       "<td>0.4633447</td>\n",
       "<td>1.1559502</td>\n",
       "<td>0.0887097</td>\n",
       "<td>0.2213125</td>\n",
       "<td>0.0463158</td>\n",
       "<td>0.9247368</td>\n",
       "<td>-53.6655348</td>\n",
       "<td>15.5950173</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999395</td>\n",
       "<td>0.0922571</td>\n",
       "<td>0.4528141</td>\n",
       "<td>1.0778502</td>\n",
       "<td>0.0866935</td>\n",
       "<td>0.2063599</td>\n",
       "<td>0.0452632</td>\n",
       "<td>0.97</td>\n",
       "<td>-54.7185908</td>\n",
       "<td>7.7850185</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0596773</td>\n",
       "<td>0.2998187</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0574018</td>\n",
       "<td>0.1914551</td>\n",
       "<td>0.03</td>\n",
       "<td>1.0</td>\n",
       "<td>-70.0181269</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100766                   0.443325           2.61158   2.61158            0.5              0.5                         0.0263158       0.0263158                  161.158   161.158\n",
       "    2        0.0200524                   0.421645           2.37416   2.49347            0.454545         0.477387                    0.0236842       0.05                       137.416   149.347\n",
       "    3        0.0300282                   0.405488           2.69072   2.559              0.515152         0.489933                    0.0268421       0.0768421                  169.072   155.9\n",
       "    4        0.040004                    0.391273           1.89933   2.3945             0.363636         0.458438                    0.0189474       0.0957895                  89.933    139.45\n",
       "    5        0.0500806                   0.375854           2.19373   2.3541             0.42             0.450704                    0.0221053       0.117895                   119.373   135.41\n",
       "    6        0.10006                     0.326515           1.84285   2.09873            0.352823         0.401813                    0.0921053       0.21                       84.2848   109.873\n",
       "    7        0.15004                     0.29288            1.63224   1.94334            0.3125           0.372062                    0.0815789       0.291579                   63.2237   94.3337\n",
       "    8        0.20002                     0.265445           1.6533    1.87086            0.316532         0.358186                    0.0826316       0.374211                   65.3298   87.0864\n",
       "    9        0.29998                     0.22512            1.36371   1.70187            0.261089         0.325831                    0.136316        0.510526                   36.3708   70.1869\n",
       "    10       0.40004                     0.195278           1.04674   1.538              0.200403         0.294458                    0.104737        0.615263                   4.67356   53.8003\n",
       "    11       0.5                         0.170958           1.03726   1.43789            0.198589         0.275292                    0.103684        0.718947                   3.72602   43.7895\n",
       "    12       0.59996                     0.148869           0.826649  1.33605            0.158266         0.255794                    0.0826316       0.801579                   -17.3351  33.6055\n",
       "    13       0.70002                     0.129764           0.767957  1.25485            0.147029         0.240248                    0.0768421       0.878421                   -23.2043  25.4851\n",
       "    14       0.79998                     0.111152           0.463345  1.15595            0.0887097        0.221313                    0.0463158       0.924737                   -53.6655  15.595\n",
       "    15       0.89994                     0.0922571          0.452814  1.07785            0.0866935        0.20636                     0.0452632       0.97                       -54.7186  7.78502\n",
       "    16       1                           0.0596773          0.299819  1                  0.0574018        0.191455                    0.03            1                          -70.0181  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.14716412316013278\n",
      "RMSE: 0.38361976377675433\n",
      "LogLoss: 0.46347712915408495\n",
      "Mean Per-Class Error: 0.3757937526837185\n",
      "AUC: 0.6690848124829848\n",
      "Gini: 0.3381696249659696\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1974456585232734: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>26099.0</td>\n",
       "<td>13560.0</td>\n",
       "<td>0.3419</td>\n",
       "<td> (13560.0/39659.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>3905.0</td>\n",
       "<td>5627.0</td>\n",
       "<td>0.4097</td>\n",
       "<td> (3905.0/9532.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>30004.0</td>\n",
       "<td>19187.0</td>\n",
       "<td>0.355</td>\n",
       "<td> (17465.0/49191.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  -----------------\n",
       "0      26099  13560  0.3419   (13560.0/39659.0)\n",
       "1      3905   5627   0.4097   (3905.0/9532.0)\n",
       "Total  30004  19187  0.355    (17465.0/49191.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1974457</td>\n",
       "<td>0.3918660</td>\n",
       "<td>230.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1116928</td>\n",
       "<td>0.5627238</td>\n",
       "<td>338.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2842587</td>\n",
       "<td>0.3550024</td>\n",
       "<td>137.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4518233</td>\n",
       "<td>0.8065093</td>\n",
       "<td>19.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.4727366</td>\n",
       "<td>0.5208333</td>\n",
       "<td>10.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0603167</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.5091984</td>\n",
       "<td>0.9999244</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2029996</td>\n",
       "<td>0.2017317</td>\n",
       "<td>223.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1889088</td>\n",
       "<td>0.6219052</td>\n",
       "<td>240.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1974457</td>\n",
       "<td>0.6242062</td>\n",
       "<td>230.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.197446     0.391866  230\n",
       "max f2                       0.111693     0.562724  338\n",
       "max f0point5                 0.284259     0.355002  137\n",
       "max accuracy                 0.451823     0.806509  19\n",
       "max precision                0.472737     0.520833  10\n",
       "max recall                   0.0603167    1         399\n",
       "max specificity              0.509198     0.999924  0\n",
       "max absolute_mcc             0.203        0.201732  223\n",
       "max min_per_class_accuracy   0.188909     0.621905  240\n",
       "max mean_per_class_accuracy  0.197446     0.624206  230"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.38 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100018</td>\n",
       "<td>0.4449025</td>\n",
       "<td>2.6012866</td>\n",
       "<td>2.6012866</td>\n",
       "<td>0.5040650</td>\n",
       "<td>0.5040650</td>\n",
       "<td>0.0260176</td>\n",
       "<td>0.0260176</td>\n",
       "<td>160.1286552</td>\n",
       "<td>160.1286552</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200037</td>\n",
       "<td>0.4214264</td>\n",
       "<td>2.1607461</td>\n",
       "<td>2.3810163</td>\n",
       "<td>0.4186992</td>\n",
       "<td>0.4613821</td>\n",
       "<td>0.0216114</td>\n",
       "<td>0.0476290</td>\n",
       "<td>116.0746088</td>\n",
       "<td>138.1016320</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300055</td>\n",
       "<td>0.4027877</td>\n",
       "<td>2.0768336</td>\n",
       "<td>2.2796221</td>\n",
       "<td>0.4024390</td>\n",
       "<td>0.4417344</td>\n",
       "<td>0.0207721</td>\n",
       "<td>0.0684012</td>\n",
       "<td>107.6833618</td>\n",
       "<td>127.9622086</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400073</td>\n",
       "<td>0.3886123</td>\n",
       "<td>2.0138993</td>\n",
       "<td>2.2131914</td>\n",
       "<td>0.3902439</td>\n",
       "<td>0.4288618</td>\n",
       "<td>0.0201427</td>\n",
       "<td>0.0885439</td>\n",
       "<td>101.3899266</td>\n",
       "<td>121.3191381</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500091</td>\n",
       "<td>0.3756632</td>\n",
       "<td>1.9929211</td>\n",
       "<td>2.1691373</td>\n",
       "<td>0.3861789</td>\n",
       "<td>0.4203252</td>\n",
       "<td>0.0199329</td>\n",
       "<td>0.1084767</td>\n",
       "<td>99.2921149</td>\n",
       "<td>116.9137335</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000183</td>\n",
       "<td>0.3258714</td>\n",
       "<td>1.8355853</td>\n",
       "<td>2.0023613</td>\n",
       "<td>0.3556911</td>\n",
       "<td>0.3880081</td>\n",
       "<td>0.0917961</td>\n",
       "<td>0.2002728</td>\n",
       "<td>83.5585269</td>\n",
       "<td>100.2361302</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500071</td>\n",
       "<td>0.2907210</td>\n",
       "<td>1.7880625</td>\n",
       "<td>1.9309477</td>\n",
       "<td>0.3464823</td>\n",
       "<td>0.3741699</td>\n",
       "<td>0.0893831</td>\n",
       "<td>0.2896559</td>\n",
       "<td>78.8062453</td>\n",
       "<td>93.0947713</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000163</td>\n",
       "<td>0.2637421</td>\n",
       "<td>1.4076317</td>\n",
       "<td>1.8001054</td>\n",
       "<td>0.2727642</td>\n",
       "<td>0.3488159</td>\n",
       "<td>0.0703945</td>\n",
       "<td>0.3600504</td>\n",
       "<td>40.7631675</td>\n",
       "<td>80.0105407</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000142</td>\n",
       "<td>0.2235013</td>\n",
       "<td>1.2526482</td>\n",
       "<td>1.6176320</td>\n",
       "<td>0.2427323</td>\n",
       "<td>0.3134571</td>\n",
       "<td>0.1252623</td>\n",
       "<td>0.4853126</td>\n",
       "<td>25.2648209</td>\n",
       "<td>61.7632039</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000122</td>\n",
       "<td>0.1944564</td>\n",
       "<td>1.1340978</td>\n",
       "<td>1.4967546</td>\n",
       "<td>0.2197601</td>\n",
       "<td>0.2900340</td>\n",
       "<td>0.1134075</td>\n",
       "<td>0.5987201</td>\n",
       "<td>13.4097751</td>\n",
       "<td>49.6754611</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000102</td>\n",
       "<td>0.1700730</td>\n",
       "<td>0.9588949</td>\n",
       "<td>1.3891870</td>\n",
       "<td>0.1858101</td>\n",
       "<td>0.2691901</td>\n",
       "<td>0.0958875</td>\n",
       "<td>0.6946076</td>\n",
       "<td>-4.1105140</td>\n",
       "<td>38.9187034</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000081</td>\n",
       "<td>0.1488376</td>\n",
       "<td>0.8162147</td>\n",
       "<td>1.2936949</td>\n",
       "<td>0.1581622</td>\n",
       "<td>0.2506861</td>\n",
       "<td>0.0816198</td>\n",
       "<td>0.7762274</td>\n",
       "<td>-18.3785338</td>\n",
       "<td>29.3694874</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000061</td>\n",
       "<td>0.1293534</td>\n",
       "<td>0.7438254</td>\n",
       "<td>1.2151444</td>\n",
       "<td>0.1441350</td>\n",
       "<td>0.2354649</td>\n",
       "<td>0.0743810</td>\n",
       "<td>0.8506085</td>\n",
       "<td>-25.6174556</td>\n",
       "<td>21.5144380</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000041</td>\n",
       "<td>0.1108183</td>\n",
       "<td>0.6410118</td>\n",
       "<td>1.1433796</td>\n",
       "<td>0.1242122</td>\n",
       "<td>0.2215587</td>\n",
       "<td>0.0640999</td>\n",
       "<td>0.9147084</td>\n",
       "<td>-35.8988228</td>\n",
       "<td>14.3379628</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000020</td>\n",
       "<td>0.0927616</td>\n",
       "<td>0.4689562</td>\n",
       "<td>1.0684454</td>\n",
       "<td>0.0908721</td>\n",
       "<td>0.2070383</td>\n",
       "<td>0.0468947</td>\n",
       "<td>0.9616030</td>\n",
       "<td>-53.1043761</td>\n",
       "<td>6.8445388</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0590042</td>\n",
       "<td>0.3839776</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0744054</td>\n",
       "<td>0.1937753</td>\n",
       "<td>0.0383970</td>\n",
       "<td>1.0</td>\n",
       "<td>-61.6022408</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100018                   0.444902           2.60129   2.60129            0.504065         0.504065                    0.0260176       0.0260176                  160.129   160.129\n",
       "    2        0.0200037                   0.421426           2.16075   2.38102            0.418699         0.461382                    0.0216114       0.047629                   116.075   138.102\n",
       "    3        0.0300055                   0.402788           2.07683   2.27962            0.402439         0.441734                    0.0207721       0.0684012                  107.683   127.962\n",
       "    4        0.0400073                   0.388612           2.0139    2.21319            0.390244         0.428862                    0.0201427       0.0885439                  101.39    121.319\n",
       "    5        0.0500091                   0.375663           1.99292   2.16914            0.386179         0.420325                    0.0199329       0.108477                   99.2921   116.914\n",
       "    6        0.100018                    0.325871           1.83559   2.00236            0.355691         0.388008                    0.0917961       0.200273                   83.5585   100.236\n",
       "    7        0.150007                    0.290721           1.78806   1.93095            0.346482         0.37417                     0.0893831       0.289656                   78.8062   93.0948\n",
       "    8        0.200016                    0.263742           1.40763   1.80011            0.272764         0.348816                    0.0703945       0.36005                    40.7632   80.0105\n",
       "    9        0.300014                    0.223501           1.25265   1.61763            0.242732         0.313457                    0.125262        0.485313                   25.2648   61.7632\n",
       "    10       0.400012                    0.194456           1.1341    1.49675            0.21976          0.290034                    0.113407        0.59872                    13.4098   49.6755\n",
       "    11       0.50001                     0.170073           0.958895  1.38919            0.18581          0.26919                     0.0958875       0.694608                   -4.11051  38.9187\n",
       "    12       0.600008                    0.148838           0.816215  1.29369            0.158162         0.250686                    0.0816198       0.776227                   -18.3785  29.3695\n",
       "    13       0.700006                    0.129353           0.743825  1.21514            0.144135         0.235465                    0.074381        0.850608                   -25.6175  21.5144\n",
       "    14       0.800004                    0.110818           0.641012  1.14338            0.124212         0.221559                    0.0640999       0.914708                   -35.8988  14.338\n",
       "    15       0.900002                    0.0927616          0.468956  1.06845            0.0908721        0.207038                    0.0468947       0.961603                   -53.1044  6.84454\n",
       "    16       1                           0.0590042          0.383978  1                  0.0744054        0.193775                    0.038397        1                          -61.6022  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:57:57</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:57:59</td>\n",
       "<td> 3.062 sec</td>\n",
       "<td>76298 obs/sec</td>\n",
       "<td>1.5226220</td>\n",
       "<td>1</td>\n",
       "<td>99951.0</td>\n",
       "<td>0.3802783</td>\n",
       "<td>0.4553597</td>\n",
       "<td>0.6859534</td>\n",
       "<td>2.6115789</td>\n",
       "<td>0.3452237</td>\n",
       "<td>0.3844228</td>\n",
       "<td>0.4645550</td>\n",
       "<td>0.6688402</td>\n",
       "<td>2.5068850</td>\n",
       "<td>0.3755972</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:01</td>\n",
       "<td> 4.515 sec</td>\n",
       "<td>81583 obs/sec</td>\n",
       "<td>3.0449089</td>\n",
       "<td>2</td>\n",
       "<td>199880.0</td>\n",
       "<td>0.3797884</td>\n",
       "<td>0.4551946</td>\n",
       "<td>0.6893369</td>\n",
       "<td>2.4548842</td>\n",
       "<td>0.3432084</td>\n",
       "<td>0.3837157</td>\n",
       "<td>0.4637102</td>\n",
       "<td>0.6707354</td>\n",
       "<td>2.4544397</td>\n",
       "<td>0.3816552</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:02</td>\n",
       "<td> 5.929 sec</td>\n",
       "<td>82905 obs/sec</td>\n",
       "<td>4.5618031</td>\n",
       "<td>3</td>\n",
       "<td>299455.0</td>\n",
       "<td>0.3798108</td>\n",
       "<td>0.4546644</td>\n",
       "<td>0.6872953</td>\n",
       "<td>2.5593474</td>\n",
       "<td>0.3660822</td>\n",
       "<td>0.3841954</td>\n",
       "<td>0.4646253</td>\n",
       "<td>0.6666972</td>\n",
       "<td>2.6432428</td>\n",
       "<td>0.3563863</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:03</td>\n",
       "<td> 7.582 sec</td>\n",
       "<td>85776 obs/sec</td>\n",
       "<td>6.0878527</td>\n",
       "<td>4</td>\n",
       "<td>399631.0</td>\n",
       "<td>0.3833328</td>\n",
       "<td>0.4624014</td>\n",
       "<td>0.6882186</td>\n",
       "<td>2.5593474</td>\n",
       "<td>0.3750504</td>\n",
       "<td>0.3871330</td>\n",
       "<td>0.4718812</td>\n",
       "<td>0.6701115</td>\n",
       "<td>2.4649288</td>\n",
       "<td>0.3870627</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:06</td>\n",
       "<td>10.107 sec</td>\n",
       "<td>71733 obs/sec</td>\n",
       "<td>7.6121809</td>\n",
       "<td>5</td>\n",
       "<td>499694.0</td>\n",
       "<td>0.3798377</td>\n",
       "<td>0.4545102</td>\n",
       "<td>0.6881884</td>\n",
       "<td>2.5071158</td>\n",
       "<td>0.3404877</td>\n",
       "<td>0.3840824</td>\n",
       "<td>0.4642912</td>\n",
       "<td>0.6691557</td>\n",
       "<td>2.5383522</td>\n",
       "<td>0.3875912</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:08</td>\n",
       "<td>11.420 sec</td>\n",
       "<td>74286 obs/sec</td>\n",
       "<td>9.1359149</td>\n",
       "<td>6</td>\n",
       "<td>599718.0</td>\n",
       "<td>0.3803389</td>\n",
       "<td>0.4567269</td>\n",
       "<td>0.6898939</td>\n",
       "<td>2.5593474</td>\n",
       "<td>0.3692060</td>\n",
       "<td>0.3845155</td>\n",
       "<td>0.4656183</td>\n",
       "<td>0.6692889</td>\n",
       "<td>2.5173741</td>\n",
       "<td>0.3575857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:09</td>\n",
       "<td>12.670 sec</td>\n",
       "<td>76750 obs/sec</td>\n",
       "<td>10.6607001</td>\n",
       "<td>7</td>\n",
       "<td>699811.0</td>\n",
       "<td>0.3800611</td>\n",
       "<td>0.4556208</td>\n",
       "<td>0.6847244</td>\n",
       "<td>2.3504211</td>\n",
       "<td>0.3445183</td>\n",
       "<td>0.3839916</td>\n",
       "<td>0.4640350</td>\n",
       "<td>0.6681922</td>\n",
       "<td>2.3915054</td>\n",
       "<td>0.3925108</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:10</td>\n",
       "<td>13.871 sec</td>\n",
       "<td>78923 obs/sec</td>\n",
       "<td>12.1840534</td>\n",
       "<td>8</td>\n",
       "<td>799810.0</td>\n",
       "<td>0.3800529</td>\n",
       "<td>0.4558997</td>\n",
       "<td>0.6850540</td>\n",
       "<td>2.8205053</td>\n",
       "<td>0.3120717</td>\n",
       "<td>0.3841183</td>\n",
       "<td>0.4648343</td>\n",
       "<td>0.6658078</td>\n",
       "<td>2.6117756</td>\n",
       "<td>0.3621801</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:11</td>\n",
       "<td>15.033 sec</td>\n",
       "<td>81064 obs/sec</td>\n",
       "<td>13.7086710</td>\n",
       "<td>9</td>\n",
       "<td>899892.0</td>\n",
       "<td>0.3796760</td>\n",
       "<td>0.4542979</td>\n",
       "<td>0.6890318</td>\n",
       "<td>2.6638105</td>\n",
       "<td>0.3758565</td>\n",
       "<td>0.3839098</td>\n",
       "<td>0.4643072</td>\n",
       "<td>0.6704357</td>\n",
       "<td>2.6642209</td>\n",
       "<td>0.3624850</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:13</td>\n",
       "<td>16.193 sec</td>\n",
       "<td>82809 obs/sec</td>\n",
       "<td>15.2324660</td>\n",
       "<td>10</td>\n",
       "<td>999920.0</td>\n",
       "<td>0.3808994</td>\n",
       "<td>0.4566182</td>\n",
       "<td>0.6866072</td>\n",
       "<td>2.5593474</td>\n",
       "<td>0.3147924</td>\n",
       "<td>0.3855863</td>\n",
       "<td>0.4676274</td>\n",
       "<td>0.6673428</td>\n",
       "<td>2.3495491</td>\n",
       "<td>0.4046269</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:14</td>\n",
       "<td>17.374 sec</td>\n",
       "<td>84153 obs/sec</td>\n",
       "<td>16.7539912</td>\n",
       "<td>11</td>\n",
       "<td>1099799.0</td>\n",
       "<td>0.3803267</td>\n",
       "<td>0.4556301</td>\n",
       "<td>0.6875346</td>\n",
       "<td>2.4026526</td>\n",
       "<td>0.3493551</td>\n",
       "<td>0.3845816</td>\n",
       "<td>0.4650365</td>\n",
       "<td>0.6677390</td>\n",
       "<td>2.3915054</td>\n",
       "<td>0.4101157</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:15</td>\n",
       "<td>18.601 sec</td>\n",
       "<td>85075 obs/sec</td>\n",
       "<td>18.2777710</td>\n",
       "<td>12</td>\n",
       "<td>1199826.0</td>\n",
       "<td>0.3796243</td>\n",
       "<td>0.4545508</td>\n",
       "<td>0.6879894</td>\n",
       "<td>2.6115789</td>\n",
       "<td>0.3238613</td>\n",
       "<td>0.3836198</td>\n",
       "<td>0.4634771</td>\n",
       "<td>0.6690848</td>\n",
       "<td>2.6012866</td>\n",
       "<td>0.3550446</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:16</td>\n",
       "<td>19.737 sec</td>\n",
       "<td>86261 obs/sec</td>\n",
       "<td>19.7992200</td>\n",
       "<td>13</td>\n",
       "<td>1299700.0</td>\n",
       "<td>0.3808349</td>\n",
       "<td>0.4575195</td>\n",
       "<td>0.6848141</td>\n",
       "<td>2.5071158</td>\n",
       "<td>0.3716243</td>\n",
       "<td>0.3850006</td>\n",
       "<td>0.4663161</td>\n",
       "<td>0.6665559</td>\n",
       "<td>2.5383522</td>\n",
       "<td>0.3568742</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:17</td>\n",
       "<td>20.930 sec</td>\n",
       "<td>87106 obs/sec</td>\n",
       "<td>21.3266864</td>\n",
       "<td>14</td>\n",
       "<td>1399969.0</td>\n",
       "<td>0.3843492</td>\n",
       "<td>0.4652862</td>\n",
       "<td>0.6818501</td>\n",
       "<td>2.7160421</td>\n",
       "<td>0.3478436</td>\n",
       "<td>0.3881900</td>\n",
       "<td>0.4733023</td>\n",
       "<td>0.6640504</td>\n",
       "<td>2.5593303</td>\n",
       "<td>0.3793987</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:58:17</td>\n",
       "<td>21.125 sec</td>\n",
       "<td>87078 obs/sec</td>\n",
       "<td>21.3266864</td>\n",
       "<td>14</td>\n",
       "<td>1399969.0</td>\n",
       "<td>0.3796243</td>\n",
       "<td>0.4545508</td>\n",
       "<td>0.6879894</td>\n",
       "<td>2.6115789</td>\n",
       "<td>0.3238613</td>\n",
       "<td>0.3836198</td>\n",
       "<td>0.4634771</td>\n",
       "<td>0.6690848</td>\n",
       "<td>2.6012866</td>\n",
       "<td>0.3550446</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  -----------  ---------------  ------------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -----------------  ---------------------------------\n",
       "    2017-03-05 14:57:57  0.000 sec                     0         0             0            nan              nan                 nan             nan              nan                              nan                nan                   nan               nan                nan\n",
       "    2017-03-05 14:57:59  3.062 sec   76298 obs/sec     1.52262   1             99951        0.380278         0.45536             0.685953        2.61158          0.345224                         0.384423           0.464555              0.66884           2.50689            0.375597\n",
       "    2017-03-05 14:58:01  4.515 sec   81583 obs/sec     3.04491   2             199880       0.379788         0.455195            0.689337        2.45488          0.343208                         0.383716           0.46371               0.670735          2.45444            0.381655\n",
       "    2017-03-05 14:58:02  5.929 sec   82905 obs/sec     4.5618    3             299455       0.379811         0.454664            0.687295        2.55935          0.366082                         0.384195           0.464625              0.666697          2.64324            0.356386\n",
       "    2017-03-05 14:58:03  7.582 sec   85776 obs/sec     6.08785   4             399631       0.383333         0.462401            0.688219        2.55935          0.37505                          0.387133           0.471881              0.670112          2.46493            0.387063\n",
       "    2017-03-05 14:58:06  10.107 sec  71733 obs/sec     7.61218   5             499694       0.379838         0.45451             0.688188        2.50712          0.340488                         0.384082           0.464291              0.669156          2.53835            0.387591\n",
       "    2017-03-05 14:58:08  11.420 sec  74286 obs/sec     9.13591   6             599718       0.380339         0.456727            0.689894        2.55935          0.369206                         0.384516           0.465618              0.669289          2.51737            0.357586\n",
       "    2017-03-05 14:58:09  12.670 sec  76750 obs/sec     10.6607   7             699811       0.380061         0.455621            0.684724        2.35042          0.344518                         0.383992           0.464035              0.668192          2.39151            0.392511\n",
       "    2017-03-05 14:58:10  13.871 sec  78923 obs/sec     12.1841   8             799810       0.380053         0.4559              0.685054        2.82051          0.312072                         0.384118           0.464834              0.665808          2.61178            0.36218\n",
       "    2017-03-05 14:58:11  15.033 sec  81064 obs/sec     13.7087   9             899892       0.379676         0.454298            0.689032        2.66381          0.375857                         0.38391            0.464307              0.670436          2.66422            0.362485\n",
       "    2017-03-05 14:58:13  16.193 sec  82809 obs/sec     15.2325   10            999920       0.380899         0.456618            0.686607        2.55935          0.314792                         0.385586           0.467627              0.667343          2.34955            0.404627\n",
       "    2017-03-05 14:58:14  17.374 sec  84153 obs/sec     16.754    11            1.0998e+06   0.380327         0.45563             0.687535        2.40265          0.349355                         0.384582           0.465036              0.667739          2.39151            0.410116\n",
       "    2017-03-05 14:58:15  18.601 sec  85075 obs/sec     18.2778   12            1.19983e+06  0.379624         0.454551            0.687989        2.61158          0.323861                         0.38362            0.463477              0.669085          2.60129            0.355045\n",
       "    2017-03-05 14:58:16  19.737 sec  86261 obs/sec     19.7992   13            1.2997e+06   0.380835         0.45752             0.684814        2.50712          0.371624                         0.385001           0.466316              0.666556          2.53835            0.356874\n",
       "    2017-03-05 14:58:17  20.930 sec  87106 obs/sec     21.3267   14            1.39997e+06  0.384349         0.465286            0.68185         2.71604          0.347844                         0.38819            0.473302              0.66405           2.55933            0.379399\n",
       "    2017-03-05 14:58:17  21.125 sec  87078 obs/sec     21.3267   14            1.39997e+06  0.379624         0.454551            0.687989        2.61158          0.323861                         0.38362            0.463477              0.669085          2.60129            0.355045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neural network\n",
    "\n",
    "# initialize nn model\n",
    "nn_model = H2ODeepLearningEstimator(\n",
    "    epochs=50,                    # read over the data 50 times, but in mini-batches\n",
    "    hidden=[100],                 # 100 hidden units in 1 hidden layer\n",
    "    input_dropout_ratio=0.2,      # randomly drop 20% of inputs for each iteration, helps w/ generalization\n",
    "    hidden_dropout_ratios=[0.05], # randomly set 5% of hidden weights to 0 each iteration, helps w/ generalization\n",
    "    activation='TanhWithDropout', # bounded activation function that allows for dropout, tanh\n",
    "    l1=0.001,                     # L1 penalty can help generalization   \n",
    "    l2=0.01,                      # L2 penalty can increase stability in presence of highly correlated inputs\n",
    "    adaptive_rate=True,           # adjust magnitude of weight updates automatically (+stability, +accuracy)\n",
    "    stopping_rounds=5,            # stop after validation error does not decrease for 5 iterations\n",
    "    score_each_iteration=True,    # score validation error on every iteration\n",
    "    model_id='nn_model')          # for easy lookup in flow\n",
    "\n",
    "# train nn model\n",
    "nn_model.train(\n",
    "    x=X,\n",
    "    y=y,\n",
    "    training_frame=train,\n",
    "    validation_frame=valid)\n",
    "\n",
    "# print model information\n",
    "nn_model\n",
    "\n",
    "# view detailed results at http://localhost:54321/flow/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6879894198982001\n",
      "0.6690848124829848\n",
      "0.6768012585175186\n"
     ]
    }
   ],
   "source": [
    "# measure nn AUC\n",
    "print(nn_model.auc(train=True))\n",
    "print(nn_model.auc(valid=True))\n",
    "print(nn_model.model_performance(test_data=test).auc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Grid Build progress: |███████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# NN with random hyperparameter search\n",
    "# train many different NN models with random hyperparameters\n",
    "# and select best model based on validation error\n",
    "\n",
    "# define random grid search parameters\n",
    "hyper_parameters = {'hidden':[[170, 320], [80, 190], [320, 160, 80], [100], [50, 50, 50, 50]],\n",
    "                    'l1':[s/1e4 for s in range(0, 1000, 100)],\n",
    "                    'l2':[s/1e5 for s in range(0, 1000, 100)],\n",
    "                    'input_dropout_ratio':[s/1e2 for s in range(0, 20, 2)]}\n",
    "\n",
    "# define search strategy\n",
    "search_criteria = {'strategy':'RandomDiscrete',\n",
    "                   'max_models':20,\n",
    "                   'max_runtime_secs':600}\n",
    "\n",
    "# initialize grid search\n",
    "gsearch = H2OGridSearch(H2ODeepLearningEstimator,\n",
    "                        hyper_params=hyper_parameters,\n",
    "                        search_criteria=search_criteria)\n",
    "\n",
    "# execute training w/ grid search\n",
    "gsearch.train(x=X,\n",
    "              y=y,\n",
    "              training_frame=train,\n",
    "              validation_frame=valid)\n",
    "\n",
    "# view detailed results at http://localhost:54321/flow/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                hidden input_dropout_ratio    l1     l2  \\\n",
      "0                [100]                0.18  0.02  0.008   \n",
      "1                [100]                 0.1  0.02  0.008   \n",
      "2                [100]                 0.1  0.06  0.006   \n",
      "3       [320, 160, 80]                 0.0  0.01  0.001   \n",
      "4           [170, 320]                0.06  0.01  0.007   \n",
      "5           [170, 320]                0.12  0.03  0.004   \n",
      "6            [80, 190]                0.18  0.02  0.008   \n",
      "7            [80, 190]                 0.1  0.03  0.009   \n",
      "8     [50, 50, 50, 50]                0.08  0.05  0.004   \n",
      "9            [80, 190]                0.18  0.06  0.005   \n",
      "10           [80, 190]                 0.0  0.06  0.008   \n",
      "11               [100]                0.02  0.04  0.006   \n",
      "12               [100]                0.02  0.06  0.004   \n",
      "13           [80, 190]                0.18  0.06  0.007   \n",
      "14          [170, 320]                0.06  0.07  0.007   \n",
      "15           [80, 190]                0.14  0.03  0.004   \n",
      "16    [50, 50, 50, 50]                0.12  0.01  0.007   \n",
      "17      [320, 160, 80]                0.02  0.01    0.0   \n",
      "18    [50, 50, 50, 50]                 0.1  0.06    0.0   \n",
      "19      [320, 160, 80]                0.16  0.01  0.003   \n",
      "\n",
      "                                                                model_ids  \\\n",
      "0   Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_9   \n",
      "1   Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_mode...   \n",
      "2   Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_4   \n",
      "3   Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_mode...   \n",
      "4   Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_6   \n",
      "5   Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_3   \n",
      "6   Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_mode...   \n",
      "7   Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_mode...   \n",
      "8   Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_mode...   \n",
      "9   Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_7   \n",
      "10  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_mode...   \n",
      "11  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_mode...   \n",
      "12  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_mode...   \n",
      "13  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_1   \n",
      "14  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_8   \n",
      "15  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_mode...   \n",
      "16  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_0   \n",
      "17  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_5   \n",
      "18  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_2   \n",
      "19  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_mode...   \n",
      "\n",
      "                logloss  \n",
      "0    0.4665108466360082  \n",
      "1    0.4672577727589049  \n",
      "2   0.49180760688559993  \n",
      "3   0.49340422513101256  \n",
      "4    0.4935917111436136  \n",
      "5    0.4940674960651805  \n",
      "6    0.4943429023102421  \n",
      "7    0.4952134113980504  \n",
      "8     0.497018064417741  \n",
      "9   0.49821296269581355  \n",
      "10  0.49823191879660195  \n",
      "11    0.498394425377021  \n",
      "12  0.49845713499201155  \n",
      "13   0.4985832770417643  \n",
      "14  0.49956120207440785  \n",
      "15   0.5065674270865724  \n",
      "16   0.5123765682901726  \n",
      "17   0.5143173692053821  \n",
      "18   0.5622461586498995  \n",
      "19   0.6299455225981917  \n",
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  Grid_DeepLearning_py_7_sid_bc2c_model_python_1488743871002_32_model_9\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.14725977717296032\n",
      "RMSE: 0.38374441647138047\n",
      "LogLoss: 0.46372711571707503\n",
      "Mean Per-Class Error: 0.3731369293059327\n",
      "AUC: 0.6717227633960028\n",
      "Gini: 0.3434455267920056\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19698055628842004: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>5491.0</td>\n",
       "<td>2663.0</td>\n",
       "<td>0.3266</td>\n",
       "<td> (2663.0/8154.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>818.0</td>\n",
       "<td>1130.0</td>\n",
       "<td>0.4199</td>\n",
       "<td> (818.0/1948.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>6309.0</td>\n",
       "<td>3793.0</td>\n",
       "<td>0.3446</td>\n",
       "<td> (3481.0/10102.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ----------------\n",
       "0      5491  2663  0.3266   (2663.0/8154.0)\n",
       "1      818   1130  0.4199   (818.0/1948.0)\n",
       "Total  6309  3793  0.3446   (3481.0/10102.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1969806</td>\n",
       "<td>0.3936596</td>\n",
       "<td>201.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1204921</td>\n",
       "<td>0.5644273</td>\n",
       "<td>328.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2445548</td>\n",
       "<td>0.3516508</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3455796</td>\n",
       "<td>0.8080578</td>\n",
       "<td>33.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.3977974</td>\n",
       "<td>0.5526316</td>\n",
       "<td>4.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0669954</td>\n",
       "<td>1.0</td>\n",
       "<td>392.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.4062546</td>\n",
       "<td>0.9985283</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2107221</td>\n",
       "<td>0.2120594</td>\n",
       "<td>178.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1889417</td>\n",
       "<td>0.6232033</td>\n",
       "<td>214.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1914947</td>\n",
       "<td>0.6268631</td>\n",
       "<td>209.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.196981     0.39366   201\n",
       "max f2                       0.120492     0.564427  328\n",
       "max f0point5                 0.244555     0.351651  131\n",
       "max accuracy                 0.34558      0.808058  33\n",
       "max precision                0.397797     0.552632  4\n",
       "max recall                   0.0669954    1         392\n",
       "max specificity              0.406255     0.998528  0\n",
       "max absolute_mcc             0.210722     0.212059  178\n",
       "max min_per_class_accuracy   0.188942     0.623203  214\n",
       "max mean_per_class_accuracy  0.191495     0.626863  209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.28 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100970</td>\n",
       "<td>0.3686537</td>\n",
       "<td>2.5929158</td>\n",
       "<td>2.5929158</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0261807</td>\n",
       "<td>0.0261807</td>\n",
       "<td>159.2915811</td>\n",
       "<td>159.2915811</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200950</td>\n",
       "<td>0.3510992</td>\n",
       "<td>2.5672434</td>\n",
       "<td>2.5801428</td>\n",
       "<td>0.4950495</td>\n",
       "<td>0.4975369</td>\n",
       "<td>0.0256674</td>\n",
       "<td>0.0518480</td>\n",
       "<td>156.7243377</td>\n",
       "<td>158.0142827</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300931</td>\n",
       "<td>0.3344523</td>\n",
       "<td>2.4645536</td>\n",
       "<td>2.5417398</td>\n",
       "<td>0.4752475</td>\n",
       "<td>0.4901316</td>\n",
       "<td>0.0246407</td>\n",
       "<td>0.0764887</td>\n",
       "<td>146.4553642</td>\n",
       "<td>154.1739841</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400911</td>\n",
       "<td>0.3237729</td>\n",
       "<td>1.9511050</td>\n",
       "<td>2.3944457</td>\n",
       "<td>0.3762376</td>\n",
       "<td>0.4617284</td>\n",
       "<td>0.0195072</td>\n",
       "<td>0.0959959</td>\n",
       "<td>95.1104967</td>\n",
       "<td>139.4445712</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500891</td>\n",
       "<td>0.3116707</td>\n",
       "<td>2.3618639</td>\n",
       "<td>2.3879422</td>\n",
       "<td>0.4554455</td>\n",
       "<td>0.4604743</td>\n",
       "<td>0.0236140</td>\n",
       "<td>0.1196099</td>\n",
       "<td>136.1863907</td>\n",
       "<td>138.7942229</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000792</td>\n",
       "<td>0.2730895</td>\n",
       "<td>1.7765324</td>\n",
       "<td>2.0825397</td>\n",
       "<td>0.3425743</td>\n",
       "<td>0.4015826</td>\n",
       "<td>0.0888090</td>\n",
       "<td>0.2084189</td>\n",
       "<td>77.6532417</td>\n",
       "<td>108.2539702</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500693</td>\n",
       "<td>0.2507378</td>\n",
       "<td>1.4890012</td>\n",
       "<td>1.8848240</td>\n",
       "<td>0.2871287</td>\n",
       "<td>0.3634565</td>\n",
       "<td>0.0744353</td>\n",
       "<td>0.2828542</td>\n",
       "<td>48.9001159</td>\n",
       "<td>88.4824026</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000594</td>\n",
       "<td>0.2354586</td>\n",
       "<td>1.5403460</td>\n",
       "<td>1.7987471</td>\n",
       "<td>0.2970297</td>\n",
       "<td>0.3468580</td>\n",
       "<td>0.0770021</td>\n",
       "<td>0.3598563</td>\n",
       "<td>54.0346026</td>\n",
       "<td>79.8747139</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000396</td>\n",
       "<td>0.2106872</td>\n",
       "<td>1.3811769</td>\n",
       "<td>1.6596030</td>\n",
       "<td>0.2663366</td>\n",
       "<td>0.3200264</td>\n",
       "<td>0.1380903</td>\n",
       "<td>0.4979466</td>\n",
       "<td>38.1176937</td>\n",
       "<td>65.9602994</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000198</td>\n",
       "<td>0.1926937</td>\n",
       "<td>1.0268974</td>\n",
       "<td>1.5014657</td>\n",
       "<td>0.1980198</td>\n",
       "<td>0.2895323</td>\n",
       "<td>0.1026694</td>\n",
       "<td>0.6006160</td>\n",
       "<td>2.6897351</td>\n",
       "<td>50.1465726</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1764488</td>\n",
       "<td>0.8985352</td>\n",
       "<td>1.3809035</td>\n",
       "<td>0.1732673</td>\n",
       "<td>0.2662839</td>\n",
       "<td>0.0898357</td>\n",
       "<td>0.6904517</td>\n",
       "<td>-10.1464818</td>\n",
       "<td>38.0903491</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999802</td>\n",
       "<td>0.1618927</td>\n",
       "<td>0.9036697</td>\n",
       "<td>1.3013776</td>\n",
       "<td>0.1742574</td>\n",
       "<td>0.2509487</td>\n",
       "<td>0.0903491</td>\n",
       "<td>0.7808008</td>\n",
       "<td>-9.6330331</td>\n",
       "<td>30.1377644</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999604</td>\n",
       "<td>0.1466439</td>\n",
       "<td>0.6880212</td>\n",
       "<td>1.2137677</td>\n",
       "<td>0.1326733</td>\n",
       "<td>0.2340546</td>\n",
       "<td>0.0687885</td>\n",
       "<td>0.8495893</td>\n",
       "<td>-31.1978775</td>\n",
       "<td>21.3767690</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999406</td>\n",
       "<td>0.1294717</td>\n",
       "<td>0.6315419</td>\n",
       "<td>1.1409985</td>\n",
       "<td>0.1217822</td>\n",
       "<td>0.2200223</td>\n",
       "<td>0.0631417</td>\n",
       "<td>0.9127310</td>\n",
       "<td>-36.8458129</td>\n",
       "<td>14.0998469</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999208</td>\n",
       "<td>0.1092314</td>\n",
       "<td>0.5391211</td>\n",
       "<td>1.0741306</td>\n",
       "<td>0.1039604</td>\n",
       "<td>0.2071279</td>\n",
       "<td>0.0539014</td>\n",
       "<td>0.9666324</td>\n",
       "<td>-46.0878891</td>\n",
       "<td>7.4130563</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0507288</td>\n",
       "<td>0.3334115</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0642928</td>\n",
       "<td>0.1928331</td>\n",
       "<td>0.0333676</td>\n",
       "<td>1.0</td>\n",
       "<td>-66.6588471</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.010097                    0.368654           2.59292   2.59292            0.5              0.5                         0.0261807       0.0261807                  159.292   159.292\n",
       "    2        0.020095                    0.351099           2.56724   2.58014            0.49505          0.497537                    0.0256674       0.051848                   156.724   158.014\n",
       "    3        0.0300931                   0.334452           2.46455   2.54174            0.475248         0.490132                    0.0246407       0.0764887                  146.455   154.174\n",
       "    4        0.0400911                   0.323773           1.9511    2.39445            0.376238         0.461728                    0.0195072       0.0959959                  95.1105   139.445\n",
       "    5        0.0500891                   0.311671           2.36186   2.38794            0.455446         0.460474                    0.023614        0.11961                    136.186   138.794\n",
       "    6        0.100079                    0.273089           1.77653   2.08254            0.342574         0.401583                    0.088809        0.208419                   77.6532   108.254\n",
       "    7        0.150069                    0.250738           1.489     1.88482            0.287129         0.363456                    0.0744353       0.282854                   48.9001   88.4824\n",
       "    8        0.200059                    0.235459           1.54035   1.79875            0.29703          0.346858                    0.0770021       0.359856                   54.0346   79.8747\n",
       "    9        0.30004                     0.210687           1.38118   1.6596             0.266337         0.320026                    0.13809         0.497947                   38.1177   65.9603\n",
       "    10       0.40002                     0.192694           1.0269    1.50147            0.19802          0.289532                    0.102669        0.600616                   2.68974   50.1466\n",
       "    11       0.5                         0.176449           0.898535  1.3809             0.173267         0.266284                    0.0898357       0.690452                   -10.1465  38.0903\n",
       "    12       0.59998                     0.161893           0.90367   1.30138            0.174257         0.250949                    0.0903491       0.780801                   -9.63303  30.1378\n",
       "    13       0.69996                     0.146644           0.688021  1.21377            0.132673         0.234055                    0.0687885       0.849589                   -31.1979  21.3768\n",
       "    14       0.799941                    0.129472           0.631542  1.141              0.121782         0.220022                    0.0631417       0.912731                   -36.8458  14.0998\n",
       "    15       0.899921                    0.109231           0.539121  1.07413            0.10396          0.207128                    0.0539014       0.966632                   -46.0879  7.41306\n",
       "    16       1                           0.0507288          0.333412  1                  0.0642928        0.192833                    0.0333676       1                          -66.6588  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.14836589527056177\n",
      "RMSE: 0.3851829374083979\n",
      "LogLoss: 0.4665108466360082\n",
      "Mean Per-Class Error: 0.37686646501331533\n",
      "AUC: 0.669025639866052\n",
      "Gini: 0.338051279732104\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.18331602718201165: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>23892.0</td>\n",
       "<td>15767.0</td>\n",
       "<td>0.3976</td>\n",
       "<td> (15767.0/39659.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>3395.0</td>\n",
       "<td>6137.0</td>\n",
       "<td>0.3562</td>\n",
       "<td> (3395.0/9532.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>27287.0</td>\n",
       "<td>21904.0</td>\n",
       "<td>0.3895</td>\n",
       "<td> (19162.0/49191.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  -----------------\n",
       "0      23892  15767  0.3976   (15767.0/39659.0)\n",
       "1      3395   6137   0.3562   (3395.0/9532.0)\n",
       "Total  27287  21904  0.3895   (19162.0/49191.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1833160</td>\n",
       "<td>0.3904441</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1332325</td>\n",
       "<td>0.5648486</td>\n",
       "<td>306.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2265355</td>\n",
       "<td>0.3486420</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4063481</td>\n",
       "<td>0.8061231</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.4063481</td>\n",
       "<td>0.4786325</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0592609</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.4063481</td>\n",
       "<td>0.9984619</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2117499</td>\n",
       "<td>0.1999202</td>\n",
       "<td>178.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1860778</td>\n",
       "<td>0.6189516</td>\n",
       "<td>218.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1833160</td>\n",
       "<td>0.6231335</td>\n",
       "<td>222.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.183316     0.390444  222\n",
       "max f2                       0.133233     0.564849  306\n",
       "max f0point5                 0.226536     0.348642  157\n",
       "max accuracy                 0.406348     0.806123  0\n",
       "max precision                0.406348     0.478632  0\n",
       "max recall                   0.0592609    1         396\n",
       "max specificity              0.406348     0.998462  0\n",
       "max absolute_mcc             0.21175      0.19992   178\n",
       "max min_per_class_accuracy   0.186078     0.618952  218\n",
       "max mean_per_class_accuracy  0.183316     0.623134  222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.38 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100018</td>\n",
       "<td>0.3718031</td>\n",
       "<td>2.3180820</td>\n",
       "<td>2.3180820</td>\n",
       "<td>0.4491870</td>\n",
       "<td>0.4491870</td>\n",
       "<td>0.0231851</td>\n",
       "<td>0.0231851</td>\n",
       "<td>131.8081968</td>\n",
       "<td>131.8081968</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200037</td>\n",
       "<td>0.3490529</td>\n",
       "<td>2.2236804</td>\n",
       "<td>2.2708812</td>\n",
       "<td>0.4308943</td>\n",
       "<td>0.4400407</td>\n",
       "<td>0.0222409</td>\n",
       "<td>0.0454259</td>\n",
       "<td>122.3680440</td>\n",
       "<td>127.0881204</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300055</td>\n",
       "<td>0.3328878</td>\n",
       "<td>2.0034102</td>\n",
       "<td>2.1817242</td>\n",
       "<td>0.3882114</td>\n",
       "<td>0.4227642</td>\n",
       "<td>0.0200378</td>\n",
       "<td>0.0654637</td>\n",
       "<td>100.3410207</td>\n",
       "<td>118.1724205</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400073</td>\n",
       "<td>0.3190451</td>\n",
       "<td>2.1607461</td>\n",
       "<td>2.1764797</td>\n",
       "<td>0.4186992</td>\n",
       "<td>0.4217480</td>\n",
       "<td>0.0216114</td>\n",
       "<td>0.0870751</td>\n",
       "<td>116.0746088</td>\n",
       "<td>117.6479676</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500091</td>\n",
       "<td>0.3084206</td>\n",
       "<td>2.0873227</td>\n",
       "<td>2.1586483</td>\n",
       "<td>0.4044715</td>\n",
       "<td>0.4182927</td>\n",
       "<td>0.0208770</td>\n",
       "<td>0.1079522</td>\n",
       "<td>108.7322677</td>\n",
       "<td>115.8648276</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000183</td>\n",
       "<td>0.2710756</td>\n",
       "<td>1.8397809</td>\n",
       "<td>1.9992146</td>\n",
       "<td>0.3565041</td>\n",
       "<td>0.3873984</td>\n",
       "<td>0.0920059</td>\n",
       "<td>0.1999580</td>\n",
       "<td>83.9780892</td>\n",
       "<td>99.9214584</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500071</td>\n",
       "<td>0.2489377</td>\n",
       "<td>1.6600439</td>\n",
       "<td>1.8861883</td>\n",
       "<td>0.3216755</td>\n",
       "<td>0.3654967</td>\n",
       "<td>0.0829836</td>\n",
       "<td>0.2829417</td>\n",
       "<td>66.0043897</td>\n",
       "<td>88.6188331</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000163</td>\n",
       "<td>0.2330295</td>\n",
       "<td>1.4600770</td>\n",
       "<td>1.7796497</td>\n",
       "<td>0.2829268</td>\n",
       "<td>0.3448521</td>\n",
       "<td>0.0730172</td>\n",
       "<td>0.3559589</td>\n",
       "<td>46.0076968</td>\n",
       "<td>77.9649663</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000142</td>\n",
       "<td>0.2087375</td>\n",
       "<td>1.2956621</td>\n",
       "<td>1.6183314</td>\n",
       "<td>0.2510673</td>\n",
       "<td>0.3135926</td>\n",
       "<td>0.1295636</td>\n",
       "<td>0.4855225</td>\n",
       "<td>29.5662093</td>\n",
       "<td>61.8331405</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000122</td>\n",
       "<td>0.1903785</td>\n",
       "<td>1.0868874</td>\n",
       "<td>1.4854772</td>\n",
       "<td>0.2106119</td>\n",
       "<td>0.2878488</td>\n",
       "<td>0.1086865</td>\n",
       "<td>0.5942090</td>\n",
       "<td>8.6887391</td>\n",
       "<td>48.5477153</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000102</td>\n",
       "<td>0.1748160</td>\n",
       "<td>0.9935158</td>\n",
       "<td>1.3870889</td>\n",
       "<td>0.1925188</td>\n",
       "<td>0.2687835</td>\n",
       "<td>0.0993496</td>\n",
       "<td>0.6935585</td>\n",
       "<td>-0.6484209</td>\n",
       "<td>38.7088881</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000081</td>\n",
       "<td>0.1604152</td>\n",
       "<td>0.8487374</td>\n",
       "<td>1.2973667</td>\n",
       "<td>0.1644643</td>\n",
       "<td>0.2513976</td>\n",
       "<td>0.0848720</td>\n",
       "<td>0.7784305</td>\n",
       "<td>-15.1262645</td>\n",
       "<td>29.7366667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000061</td>\n",
       "<td>0.1453477</td>\n",
       "<td>0.7522184</td>\n",
       "<td>1.2194906</td>\n",
       "<td>0.1457613</td>\n",
       "<td>0.2363071</td>\n",
       "<td>0.0752203</td>\n",
       "<td>0.8536509</td>\n",
       "<td>-24.7781603</td>\n",
       "<td>21.9490604</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000041</td>\n",
       "<td>0.1282796</td>\n",
       "<td>0.6305206</td>\n",
       "<td>1.1458712</td>\n",
       "<td>0.1221793</td>\n",
       "<td>0.2220415</td>\n",
       "<td>0.0630508</td>\n",
       "<td>0.9167016</td>\n",
       "<td>-36.9479419</td>\n",
       "<td>14.5871222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000020</td>\n",
       "<td>0.1090739</td>\n",
       "<td>0.4825948</td>\n",
       "<td>1.0721755</td>\n",
       "<td>0.0935149</td>\n",
       "<td>0.2077611</td>\n",
       "<td>0.0482585</td>\n",
       "<td>0.9649601</td>\n",
       "<td>-51.7405212</td>\n",
       "<td>7.2175505</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0489660</td>\n",
       "<td>0.3504058</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0679000</td>\n",
       "<td>0.1937753</td>\n",
       "<td>0.0350399</td>\n",
       "<td>1.0</td>\n",
       "<td>-64.9594219</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain       cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  ---------  -----------------\n",
       "    1        0.0100018                   0.371803           2.31808   2.31808            0.449187         0.449187                    0.0231851       0.0231851                  131.808    131.808\n",
       "    2        0.0200037                   0.349053           2.22368   2.27088            0.430894         0.440041                    0.0222409       0.0454259                  122.368    127.088\n",
       "    3        0.0300055                   0.332888           2.00341   2.18172            0.388211         0.422764                    0.0200378       0.0654637                  100.341    118.172\n",
       "    4        0.0400073                   0.319045           2.16075   2.17648            0.418699         0.421748                    0.0216114       0.0870751                  116.075    117.648\n",
       "    5        0.0500091                   0.308421           2.08732   2.15865            0.404472         0.418293                    0.020877        0.107952                   108.732    115.865\n",
       "    6        0.100018                    0.271076           1.83978   1.99921            0.356504         0.387398                    0.0920059       0.199958                   83.9781    99.9215\n",
       "    7        0.150007                    0.248938           1.66004   1.88619            0.321675         0.365497                    0.0829836       0.282942                   66.0044    88.6188\n",
       "    8        0.200016                    0.23303            1.46008   1.77965            0.282927         0.344852                    0.0730172       0.355959                   46.0077    77.965\n",
       "    9        0.300014                    0.208737           1.29566   1.61833            0.251067         0.313593                    0.129564        0.485522                   29.5662    61.8331\n",
       "    10       0.400012                    0.190378           1.08689   1.48548            0.210612         0.287849                    0.108687        0.594209                   8.68874    48.5477\n",
       "    11       0.50001                     0.174816           0.993516  1.38709            0.192519         0.268784                    0.0993496       0.693559                   -0.648421  38.7089\n",
       "    12       0.600008                    0.160415           0.848737  1.29737            0.164464         0.251398                    0.084872        0.778431                   -15.1263   29.7367\n",
       "    13       0.700006                    0.145348           0.752218  1.21949            0.145761         0.236307                    0.0752203       0.853651                   -24.7782   21.9491\n",
       "    14       0.800004                    0.12828            0.630521  1.14587            0.122179         0.222042                    0.0630508       0.916702                   -36.9479   14.5871\n",
       "    15       0.900002                    0.109074           0.482595  1.07218            0.0935149        0.207761                    0.0482585       0.96496                    -51.7405   7.21755\n",
       "    16       1                           0.048966           0.350406  1                  0.0679           0.193775                    0.0350399       1                          -64.9594   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:59:33</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:59:33</td>\n",
       "<td> 1 min 14.205 sec</td>\n",
       "<td>160107 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>65644.0</td>\n",
       "<td>0.3839785</td>\n",
       "<td>0.4652994</td>\n",
       "<td>0.6700643</td>\n",
       "<td>2.2878669</td>\n",
       "<td>0.3757672</td>\n",
       "<td>0.3850745</td>\n",
       "<td>0.4674797</td>\n",
       "<td>0.6674973</td>\n",
       "<td>2.3075929</td>\n",
       "<td>0.3717753</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:59:36</td>\n",
       "<td> 1 min 17.521 sec</td>\n",
       "<td>183568 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>656440.0</td>\n",
       "<td>0.3837444</td>\n",
       "<td>0.4637271</td>\n",
       "<td>0.6717228</td>\n",
       "<td>2.5929158</td>\n",
       "<td>0.3445852</td>\n",
       "<td>0.3851829</td>\n",
       "<td>0.4665108</td>\n",
       "<td>0.6690256</td>\n",
       "<td>2.3180820</td>\n",
       "<td>0.3895428</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -----------------  ---------------------------------\n",
       "    2017-03-05 14:59:33  0.000 sec                           0         0             0          nan              nan                 nan             nan              nan                              nan                nan                   nan               nan                nan\n",
       "    2017-03-05 14:59:33  1 min 14.205 sec  160107 obs/sec    1         1             65644      0.383978         0.465299            0.670064        2.28787          0.375767                         0.385075           0.46748               0.667497          2.30759            0.371775\n",
       "    2017-03-05 14:59:36  1 min 17.521 sec  183568 obs/sec    10        10            656440     0.383744         0.463727            0.671723        2.59292          0.344585                         0.385183           0.466511              0.669026          2.31808            0.389543"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show grid search results\n",
    "gsearch.show()\n",
    "\n",
    "# select best model\n",
    "nn_model2 = gsearch.get_grid()[0]\n",
    "\n",
    "# print model information\n",
    "nn_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6717227633960028\n",
      "0.669025639866052\n",
      "0.675823306490083\n"
     ]
    }
   ],
   "source": [
    "# measure nn AUC\n",
    "print(nn_model2.auc(train=True))\n",
    "print(nn_model2.auc(valid=True))\n",
    "print(nn_model2.model_performance(test_data=test).auc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartialDependencePlot progress: |█████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAPwCAYAAAA2yWiMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118b67320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# partial dependence plots are a powerful machine learning interpretation tool\n",
    "# to calculate partial dependence across the domain a variable\n",
    "# hold column of interest at constant value\n",
    "# find the mean prediction of the model with this column constant\n",
    "# repeat for multiple values of the variable of interest\n",
    "# h2o has a built-in function for partial dependence as well\n",
    "par_dep_dti1 = nn_model2.partial_plot(data=train, cols=['STD_IMP_REP_dti'], server=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_bc2c closed.\n"
     ]
    }
   ],
   "source": [
    "# shutdown h2o\n",
    "h2o.cluster().shutdown(prompt=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
